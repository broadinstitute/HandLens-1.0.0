{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import cv2\n",
    "import imutils\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOD threshold from negative control/low-concentration data\n",
    "\n",
    "This script estimates the detection threshold using the method from Armbruster and Pry in \"Limit of Blank, Limit of Detection and Limit of Quantitation\":\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2556583/\n",
    "\n",
    "with the formula:\n",
    "\n",
    "LOB(controls) = Mean(controls) + 1.65 SD(controls)\n",
    "\n",
    "Threshold = LOB(controls) + 1.65 SD(low-concentration samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files with negative controls and low concentration\n",
    "\n",
    "filename_cont = 'images/n2-controls.jpg'\n",
    "filename_lowc = 'images/n2-low_concentration.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utilities\n",
    "\n",
    "def makeOrderedBox(rect):\n",
    "    \"\"\"\n",
    "    Return a 4-element tuple representing the corners of a box:\n",
    "        idx 0 = top left corner   \n",
    "        idx 1 = top right corner \n",
    "        idx 2 = bottom right corner\n",
    "        idx 3 = botton left corner\n",
    "    \"\"\"\n",
    "    box0 = cv2.boxPoints(rect)\n",
    "    box0 = np.int0(box0)\n",
    "    \n",
    "    xval = [pt[0] for pt in box0]\n",
    "    yval = [pt[1] for pt in box0]\n",
    "    \n",
    "    x0 = np.mean(xval)\n",
    "    y0 = np.mean(yval)\n",
    "  \n",
    "    angles = []\n",
    "    for i in range(0, len(box0)):\n",
    "        xi = box0[i][0]\n",
    "        yi = box0[i][1]        \n",
    "        x = xi - x0\n",
    "        y = yi - y0\n",
    "        a = np.arctan2(y, x)\n",
    "        val = [a, i]\n",
    "        angles += [val]\n",
    "\n",
    "    angles.sort(key=lambda val: val[0], reverse=False)    \n",
    "    box = np.array([box0[val[1]] for val in angles])\n",
    "    \n",
    "    return box\n",
    "\n",
    "def boxMinX(box):\n",
    "    return min([pt[0] for pt in box])\n",
    "\n",
    "def boxMaxX(box):  \n",
    "    return max([pt[0] for pt in box])\n",
    "\n",
    "def boxMinY(box):\n",
    "    return min([pt[1] for pt in box])\n",
    "\n",
    "def boxMaxY(box):\n",
    "    return max([pt[1] for pt in box])\n",
    "\n",
    "def boxArea(box):\n",
    "    x0 = np.mean([pt[0] for pt in box])\n",
    "    y0 = np.mean([pt[1] for pt in box])\n",
    "    p0 = np.array([x0, y0])\n",
    "    \n",
    "    area = 0\n",
    "    n = len(box)\n",
    "    for i in range(0, n):\n",
    "        p1 = box[i]\n",
    "        if i < n - 1:\n",
    "            p2 = box[i + 1]\n",
    "        else:\n",
    "            p2 = box[0]\n",
    "            \n",
    "        # Heron's Formula\n",
    "        a = np.linalg.norm(p1-p0)\n",
    "        b = np.linalg.norm(p2-p0)\n",
    "        c = np.linalg.norm(p1-p2)\n",
    "        s = (a + b + c) / 2\n",
    "        triarea = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "        \n",
    "        area += triarea        \n",
    "        \n",
    "    return area\n",
    "\n",
    "def rectArea(rect):\n",
    "    return rect[1][0]*rect[1][1]\n",
    "\n",
    "def pointDistance(p1, p2):\n",
    "    \"\"\"\n",
    "    Given two poiints, each represented by a tuple (x1, y1), calculate the eucalidian distance\n",
    "    between them.\n",
    "    \"\"\"\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5\n",
    "\n",
    "def boxesIntersection(box1, box2, img_shape):\n",
    "    # Calculate the total intersection area of two boxes:\n",
    "    \n",
    "    # first sort the points in the boxes as (x,y) in descending order:\n",
    "    box1.sort()\n",
    "    box2.sort()\n",
    "    \n",
    "    blanked_image = np.zeros( shape = (img_shape[0], img_shape[1], 1), dtype = \"uint8\")\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    \n",
    "    return cv2.countNonZero(blanked_image)\n",
    "\n",
    "def applyClahetoRGB(bgr_imb):\n",
    "    \n",
    "    lab= cv2.cvtColor(bgr_imb, cv2.COLOR_BGR2LAB)\n",
    "    # Split lab image to different channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    \n",
    "    #Convert image from LAB Color model to RGB model\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return final\n",
    "\n",
    "def intersectLines(pt1, pt2, ptA, ptB): \n",
    "    \"\"\" this returns the intersection of Line(pt1,pt2) and Line(ptA,ptB)\n",
    "        https://www.cs.hmc.edu/ACM/lectures/intersections.html    \n",
    "        \n",
    "        returns a tuple: (xi, yi, valid, r, s), where\n",
    "        (xi, yi) is the intersection\n",
    "        r is the scalar multiple such that (xi,yi) = pt1 + r*(pt2-pt1)\n",
    "        s is the scalar multiple such that (xi,yi) = pt1 + s*(ptB-ptA)\n",
    "            valid == 0 if there are 0 or inf. intersections (invalid)\n",
    "            valid == 1 if it has a unique intersection ON the segment    \"\"\"\n",
    "\n",
    "    DET_TOLERANCE = 0.00000001\n",
    "\n",
    "    # the first line is pt1 + r*(pt2-pt1)\n",
    "    # in component form:\n",
    "    x1, y1 = pt1;   x2, y2 = pt2\n",
    "    dx1 = x2 - x1;  dy1 = y2 - y1\n",
    "\n",
    "    # the second line is ptA + s*(ptB-ptA)\n",
    "    x, y = ptA;   xB, yB = ptB;\n",
    "    dx = xB - x;  dy = yB - y;\n",
    "\n",
    "    # we need to find the (typically unique) values of r and s\n",
    "    # that will satisfy\n",
    "    #\n",
    "    # (x1, y1) + r(dx1, dy1) = (x, y) + s(dx, dy)\n",
    "    #\n",
    "    # which is the same as\n",
    "    #\n",
    "    #    [ dx1  -dx ][ r ] = [ x-x1 ]\n",
    "    #    [ dy1  -dy ][ s ] = [ y-y1 ]\n",
    "    #\n",
    "    # whose solution is\n",
    "    #\n",
    "    #    [ r ] = _1_  [  -dy   dx ] [ x-x1 ]\n",
    "    #    [ s ] = DET  [ -dy1  dx1 ] [ y-y1 ]\n",
    "    #\n",
    "    # where DET = (-dx1 * dy + dy1 * dx)\n",
    "    #\n",
    "    # if DET is too small, they're parallel\n",
    "    #\n",
    "    DET = (-dx1 * dy + dy1 * dx)\n",
    "\n",
    "    if math.fabs(DET) < DET_TOLERANCE: return (0,0,0,0,0)\n",
    "\n",
    "    # now, the determinant should be OK\n",
    "    DETinv = 1.0/DET\n",
    "\n",
    "    # find the scalar amount along the \"self\" segment\n",
    "    r = DETinv * (-dy  * (x-x1) +  dx * (y-y1))\n",
    "\n",
    "    # find the scalar amount along the input line\n",
    "    s = DETinv * (-dy1 * (x-x1) + dx1 * (y-y1))\n",
    "\n",
    "    # return the average of the two descriptions\n",
    "    xi = (x1 + r*dx1 + x + s*dx)/2.0\n",
    "    yi = (y1 + r*dy1 + y + s*dy)/2.0\n",
    "    return ( xi, yi, 1, r, s )\n",
    "\n",
    "def line(p1, p2):\n",
    "    A = (p1[1] - p2[1])\n",
    "    B = (p2[0] - p1[0])\n",
    "    C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "    return A, B, -C\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return x,y\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def rotate_image(img, center, angle, width, height):\n",
    "\n",
    "   shape = (img.shape[1], img.shape[0]) # (length, height)\n",
    "\n",
    "   matrix = cv2.getRotationMatrix2D((center[0], center[1]), angle, 1 )\n",
    "   rotated = cv2.warpAffine( img, matrix, shape )\n",
    "\n",
    "   x = int( center[0] - width/2  )\n",
    "   y = int( center[1] - height/2 )\n",
    "\n",
    "   cropped = rotated[ y:y+height, x:x+width ]\n",
    "\n",
    "   return cropped    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual detection code, all in a single function:\n",
    "\n",
    "def getPeak(data):\n",
    "    nrows = data.shape[0]\n",
    "    start = int(nrows/2)    \n",
    "    values = np.array([])\n",
    "    for r in range(0, nrows):    \n",
    "        values = np.append(values, np.mean(data[r]))\n",
    "    \n",
    "    v = values[start:-1]\n",
    "    mean = np.mean(v[0:int(len(v)/2)])\n",
    "    std = np.std(v[0:int(len(v)/2)])\n",
    "    \n",
    "    i = np.argmin(v)\n",
    "    peak = np.min(v)\n",
    "    return i, peak, v\n",
    "\n",
    "def getPeakValues(filename):\n",
    "    # The maximum and minimum allowed ratios of the sides of the green box\n",
    "    maxGreenBoxRatio = 140.0/528\n",
    "    minGreenBoxRatio = 102.0/578\n",
    "\n",
    "    # The maximum allowed ratio of the sides of the final deteted strip\n",
    "    maxStripBoxRatio = 70/480\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the sides of the box defined by the red arrows\n",
    "    maxRedBoxRatio = 42.0/91\n",
    "    minRedBoxRatio = 14.0/104\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the areas of green boxes and red arrow-bounding boxes\n",
    "    maxRedGreenBoxRatio = 3500.0/4000\n",
    "    minRedGreenBoxRatio = 2000.0/4500\n",
    "    # minRedGreenIntersection = 1000.0/4500\n",
    "\n",
    "    # Minimum intensity for binary thresholding of the top portion of the strips\n",
    "    minStripThreshold = 190\n",
    "\n",
    "    # Sensitive area of the strip\n",
    "    stripWidth = 200\n",
    "    stripHeight = 2000\n",
    "    stripHoldY = 900\n",
    "    # maxPeakAlign = 50\n",
    "\n",
    "    # Percentage of the margins to be removed\n",
    "    marginFraction = 0.2\n",
    "\n",
    "    # Red is at the beginning/end of the hue range, so it covers the [0-15] and the [170, 180] \n",
    "    # (hue in OpenCV varies  between 0 and 180 degrees)\n",
    "    lower_red1 = np.array([0, 50, 50]) \n",
    "    upper_red1 = np.array([13, 255, 255])\n",
    "    lower_red2 = np.array([170, 50, 50]) \n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Green is between 20 and 90 (these ranges can be adjusted)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "\n",
    "    # We can also use a large color range to encapsulate both red and green:\n",
    "    lower_redgreen1 = np.array([0, 50, 50]) \n",
    "    upper_redgreen1 = np.array([83, 255, 255])\n",
    "    lower_redgreen2 = np.array([170, 50, 50]) \n",
    "    upper_redgreen2 = np.array([180, 255, 255])    \n",
    "    \n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    \n",
    "    # Processing Step 1: detecting the colored area in the strips\n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    # First, use CLAHE to improve image quality:\n",
    "    # plt.subplot(2, 1, 1)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # image = applyClahetoRGB(image)\n",
    "    # plt.subplot(2, 1, 2)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # First, convert the image to HSV color space, which makes the color detection straightforward\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # These strips have red arrows on a green background, so we define two masks, one for red and the other for green\n",
    "\n",
    "    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1) \n",
    "    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2) \n",
    "\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    red_mask = red_mask1 + red_mask2\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    redgreen_mask1 = cv2.inRange(hsv, lower_redgreen1, upper_redgreen1) \n",
    "    redgreen_mask2 = cv2.inRange(hsv, lower_redgreen2, upper_redgreen2) \n",
    "    mask = redgreen_mask1 + redgreen_mask2\n",
    "    \n",
    "    # Processing Step 2a: determining the bounding boxes for the red arrows.\n",
    "    # Because the red hue seems to be well-conserved between images,\n",
    "    # we have a high confidence of putting a box around all the red arrows. \n",
    "    cnts = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    red_boxes = []\n",
    "    red_rectangles = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( top-left corner(x,y),  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        redBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if redBoxRatio < minRedBoxRatio or maxRedBoxRatio < redBoxRatio: continue\n",
    "        red_boxes += [box[0:]]\n",
    "        red_rectangles += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 3, (255,0,0), -1)    \n",
    "    \n",
    "    # Processing Step 2b: finding green box candidates\n",
    "    # Stage 1:\n",
    "    #     Given a masked version of the image which includes red to green hues,\n",
    "    #     find all green contours\n",
    "    # Stage 2:\n",
    "    #     Declare a green contour to be a green_rect_candidate to be further \n",
    "    #     analyzed if the ratio of the sides of the contour are similar to that\n",
    "    #     observed in the Sherlock strips. \n",
    "    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    green_box_candidates = []\n",
    "    green_rect_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( (x,y) of middle of top side of rect,  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        greenBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if greenBoxRatio < minGreenBoxRatio or maxGreenBoxRatio < greenBoxRatio: continue\n",
    "\n",
    "        area = boxArea(box)\n",
    "        green_box_candidates += [box[0:]]\n",
    "        green_rect_candidates += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 2c: filter the green_box_candidates based on size (imputed from\n",
    "    # the red box areas) and shape (ratio of lengths of the sides).\n",
    "    # Stage 1:\n",
    "    #     Mark all candidate green boxes which are within a particular size range\n",
    "    #     of a red box. Because we can put bounding boxes around red arrows with a \n",
    "    #     high confidence, and there is little-to-no red hue in the source image \n",
    "    #     excluding the red arrows, we can impute that the largest of these marked\n",
    "    #     are the green boxes around the arrows (the contrary would suggest a large\n",
    "    #     green spot in the source image, or some severe hue errors)\n",
    "    # Stage 2:\n",
    "    #     Sort the marked boxes by size; chose the second largest marked box as a\n",
    "    #     representative green box\n",
    "    # Stage 3:\n",
    "    #     Filter out marked green boxes which are not a similar size as the\n",
    "    #     representative green box.\n",
    "\n",
    "    green_boxes = {}\n",
    "    green_rects = {}\n",
    "    for i, red_box in enumerate(red_boxes):\n",
    "        red_box_area = boxArea(red_box)*1.0\n",
    "        for j, green_box in enumerate(green_box_candidates):\n",
    "            green_box_area = boxArea(green_box)*1.0\n",
    "            redGreenBoxRatio = red_box_area/green_box_area\n",
    "            if minRedGreenBoxRatio < redGreenBoxRatio < maxRedGreenBoxRatio:\n",
    "                # now check for intersections:\n",
    "                green_boxes[j] = True\n",
    "                green_rects[j] = True\n",
    "\n",
    "    green_boxes = [green_box_candidates[j] for j in green_boxes]\n",
    "    green_rects = [green_rect_candidates[j] for j in green_rects]\n",
    "    green_boxes.sort(key = lambda box : boxArea(box), reverse=True)\n",
    "    green_rects.sort(key = lambda rect : rectArea(rect), reverse=True)\n",
    "\n",
    "    if len(green_rects) < 2:\n",
    "        raise Exception('Not enough strips')\n",
    "    if rectArea(green_rects[0]) < 1.25* rectArea(green_rects[1]):\n",
    "        greenBoxArea = rectArea(green_rects[1])\n",
    "        green_rect_len = max(green_rects[1][1][0], green_rects[1][1][1])\n",
    "    elif len(green_boxes) < 3 \\\n",
    "            and rectArea(green_rects[1]) < 1.25* rectArea(green_rects[2]):\n",
    "        greenBoxArea = rectArea(green_rects[2])\n",
    "        green_rect_len = max(green_rects[2][1][0], green_rects[2][1][1])\n",
    "    else:\n",
    "        raise Exception('Too much noise in image')\n",
    "\n",
    "    center_boxes = [box for box in green_boxes \n",
    "                     if 0.8*greenBoxArea < boxArea(box) < 1.25*greenBoxArea]\n",
    "    greenBoxArea = statistics.median([boxArea(box) for box in center_boxes])\n",
    "\n",
    "    # Processing Step 3: binary thresholding of the entire image to extract the top part of the strips\n",
    "    ret, thresh = cv2.threshold(image, minStripThreshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Processing Step 4: detect boundary boxes for the top of the strips\n",
    "    grayscale = cv2.cvtColor(thresh, cv2.COLOR_BGR2GRAY)\n",
    "    cnts = cv2.findContours(grayscale, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    # Minimum area of the top strip boxes\n",
    "    minTopBoxArea = 1.8 * greenBoxArea\n",
    "    # Maximum of the top strip boxes\n",
    "    maxTopBoxArea = 5 * greenBoxArea\n",
    "\n",
    "    top_box_candidates = []\n",
    "    top_rects_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        area = boxArea(box)\n",
    "        if area < minTopBoxArea/15 or maxTopBoxArea < area: \n",
    "            continue\n",
    "\n",
    "        top_box_candidates += [box]\n",
    "        top_rects_candidates += [rect]\n",
    "    \n",
    "    # In some cases, the strip signal is so strong that a continuous box gets split up into two boxes. \n",
    "    # We fix this by merging two boxes if the bottom left and top left corners of the respective boxes,\n",
    "    # and the  right and top right corners of the respective boxes are within a threshold distance of\n",
    "    # # each other. \n",
    "    top_boxes = []\n",
    "    top_box_candidates.sort(key = lambda item : item[1][1])\n",
    "    distance_threshold = green_rect_len * 0.15\n",
    "    merged_boxes = {}\n",
    "    tmp = image.copy()\n",
    "    for i in range(0, len(top_box_candidates)):\n",
    "        upper_box = top_box_candidates[i]\n",
    "        if i in merged_boxes:\n",
    "            continue\n",
    "        current_merged_upper_box = upper_box\n",
    "        for j in range(i, len(top_box_candidates)):\n",
    "            lower_box = top_box_candidates[j]\n",
    "            if pointDistance(current_merged_upper_box[3], lower_box[0]) < distance_threshold and \\\n",
    "                    pointDistance(current_merged_upper_box[2], lower_box[1]) < distance_threshold:\n",
    "                # Sometimes the arrows get detected in this step as false boxes -- to filter for this, \n",
    "                # we make sure that boxes can only be concatenated if they have similar width:\n",
    "                if pointDistance(current_merged_upper_box[3], current_merged_upper_box[2]) < \\\n",
    "                        pointDistance(lower_box[0], lower_box[1])*1.5:\n",
    "                    current_merged_upper_box = np.array([current_merged_upper_box[0], \n",
    "                                                         current_merged_upper_box[1], \n",
    "                                                         lower_box[2], lower_box[3]])\n",
    "\n",
    "                    if minTopBoxArea < boxArea(current_merged_upper_box): \n",
    "                        merged_boxes[j] =  True\n",
    "        else:\n",
    "            stripBoxRatio = pointDistance(current_merged_upper_box[0], \n",
    "                                          current_merged_upper_box[1])/ \\\n",
    "                                          pointDistance(current_merged_upper_box[0],\n",
    "                                                        current_merged_upper_box[3])\n",
    "            if minTopBoxArea < boxArea(current_merged_upper_box) and \\\n",
    "                    stripBoxRatio < maxStripBoxRatio: \n",
    "                top_boxes.append(current_merged_upper_box) \n",
    "\n",
    "    for box in top_boxes:\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 5)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 5: construct the boxes that enclose the sensitive strip area\n",
    "    # First, order the top boxes from left to right\n",
    "    top_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "    # Find the red boxes which bound arrows, and then\n",
    "    # order them left to right\n",
    "    red_boxes.sort(key=lambda box: boxArea(box), reverse=True)\n",
    "    red_boxes = red_boxes[0:len(top_boxes)]\n",
    "    red_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "    num_boxes = len(top_boxes)\n",
    "    strip_boxes = []\n",
    "    for i in range(0, num_boxes):\n",
    "        tbox = top_boxes[i]\n",
    "        rbox = red_boxes[i]    \n",
    "\n",
    "        # The corners are expected to be received in the following order:\n",
    "        # 0 = botton left corner\n",
    "        # 1 = top left corner   \n",
    "        # 2 = top right corner \n",
    "        # 3 = bottom right corner\n",
    "\n",
    "        tp0, tp1, tp2, tp3 = tbox[3], tbox[0], tbox[1], tbox[2]\n",
    "        rp0, rp1, rp2, rp3 = rbox[3], rbox[0], rbox[1], rbox[2]\n",
    "\n",
    "        # The intersection of the lines defining the sides of the strip (tp1-tp0 and tp2-tp3)\n",
    "        # with the bottom edge of the red box defines the bottom corners of the area of interest\n",
    "        res1 = intersection(line(tp1, tp0), line(rp0, rp3))\n",
    "        res2 = intersection(line(tp2, tp3), line(rp0, rp3)) \n",
    "\n",
    "        assert(res1 != False and res2 != False), \"Top and center boxes are not intersecting\"\n",
    "\n",
    "        p1 = np.array([int(round(res1[0])), int(round(res1[1]))])\n",
    "        p2 = np.array([int(round(res2[0])), int(round(res2[1]))])\n",
    "\n",
    "        sbox = np.array([p1, tp1, tp2, p2])\n",
    "        strip_boxes += [sbox]\n",
    "    \n",
    "    # Processing Step 6: Extract the strips into separate images\n",
    "    ref_box = np.array([[0, 0],[0, stripHeight],[stripWidth, stripHeight],[stripWidth, 0]], dtype=float)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "#     fig, plots = plt.subplots(1, len(strip_boxes)*3, figsize=(10, 10))\n",
    "    idx = 0\n",
    "    tmp = image.copy()\n",
    "    raw_strip_images = []\n",
    "    for sbx in strip_boxes:\n",
    "        center = (statistics.mean([sbx[0][0], sbx[1][0], sbx[2][0], sbx[3][0]]),\n",
    "                  statistics.mean([sbx[0][1], sbx[1][1], sbx[2][1], sbx[3][1]]))\n",
    "        angle = -1*np.degrees(np.arctan2(sbx[0][0]-sbx[1][0], sbx[0][1] - sbx[1][1]))\n",
    "        #angle = angle if sbx[0][0] < sbx[1][0] else angle*-1\n",
    "        width = int(pointDistance(sbx[1], sbx[2]))\n",
    "        height = int(pointDistance(sbx[0], sbx[1]))\n",
    "#         print(angle)\n",
    "#         print(width)\n",
    "        straigtened_strip = rotate_image(image, center, angle, width, \n",
    "                                                    height)\n",
    "        # Spurious hits often occur at the edges of the strip, so let's\n",
    "        # crop them away\n",
    "        cropped_strip = straigtened_strip[:, \n",
    "                                          int(straigtened_strip.shape[1]*0.1):\n",
    "                                          int(straigtened_strip.shape[1]*0.9)]\n",
    "\n",
    "#         plots[idx].imshow(cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        hsv = cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2HSV)\n",
    "        green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        cnts = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        # Create a copy of the image to draw the bounding boxes on\n",
    "        tmp = cropped_strip.copy()\n",
    "        colored_box_cutoff = tmp.shape[0]\n",
    "        for c in cnts:\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0: continue\n",
    "\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = makeOrderedBox(rect)\n",
    "            if boxArea(box) > 0.10*greenBoxArea:\n",
    "                if box[0][1] < colored_box_cutoff:\n",
    "                    colored_box_cutoff = box[0][1]\n",
    "            tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "            tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 10, (255,0,0), -1)\n",
    "        #plots[idx + 0].imshow(cv2.cvtColor(green_mask, cv2.COLOR_BGR2RGB))\n",
    "#         plots[idx + 0].imshow(cv2.cvtColor(tmp, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        colored_box_cutoff = colored_box_cutoff\n",
    "        final_strip = straigtened_strip[0:colored_box_cutoff, :]\n",
    "#         plots[idx + 1].imshow(cv2.cvtColor(final_strip, cv2.COLOR_BGR2RGB))\n",
    "    #     h, status = cv2.findHomography(final_strip, ref_box)\n",
    "    #     img = cv2.warpPerspective(image, h, (stripWidth, stripHeight))\n",
    "    #     raw_strip_images += [img]\n",
    "        height = final_strip.shape[0]\n",
    "        width = final_strip.shape[1]\n",
    "        h, status = cv2.findHomography(np.array([(0,height), (0,0), (width, 0), (width, height)]), ref_box)\n",
    "        img = cv2.warpPerspective(final_strip, h, (stripWidth, stripHeight))\n",
    "        raw_strip_images += [img]\n",
    "#         plots[idx + 2].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        idx += 3    \n",
    "    \n",
    "    # Processing Step 7: Crop the images to remove the grip of the strips, and the vertical borders\n",
    "    norm_strip_images = []\n",
    "#     fig, plots = plt.subplots(1, len(raw_strip_images), figsize=(10, 10))\n",
    "    idx = 0\n",
    "    for img in raw_strip_images:\n",
    "        # Crop out the top and the bottom parts of the strip, and applying bilateral filtering for smoothing\n",
    "        # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
    "        x0 = int(marginFraction * stripWidth)\n",
    "        x1 = int((1 - marginFraction) * stripWidth)\n",
    "        y0 = 0\n",
    "        y1 = stripHoldY\n",
    "\n",
    "        crop = img[y0:y1, x0:x1]\n",
    "        nimg = cv2.bilateralFilter(crop, 9, 75, 75)\n",
    "        nimg = nimg[30:, :]\n",
    "        norm_strip_images += [nimg]\n",
    "\n",
    "        vimg = cv2.flip(nimg, 0)\n",
    "#         if idx == 1: plots[idx].axis('off')\n",
    "#         plots[idx].imshow(cv2.cvtColor(vimg, cv2.COLOR_BGR2RGB))\n",
    "        idx += 1    \n",
    "    \n",
    "    # Processing Step 7b: Normalize HSV values\n",
    "    correction_method = 'clahe' # {'linear', 'clahe', 'gray', 'he'}\n",
    "#     fig, plots = plt.subplots(1, len(raw_strip_images), figsize=(10, 10))\n",
    "    idx = 0\n",
    "    hew_corrected_norm_strip_images = []\n",
    "    for nimg in norm_strip_images:\n",
    "        hsv = cv2.cvtColor(nimg, cv2.COLOR_BGR2HSV)\n",
    "        # determine the hsv color of this strip\n",
    "        if correction_method == 'linear':\n",
    "            # We chose a standard hsv value to normalize all of our images to:\n",
    "            standard_hsv = [16.0/1.5, 17.0/1.5, 243.0/1.5]\n",
    "            # standard_hsv = [16.0, 17.0, 243.0]\n",
    "\n",
    "            rows_hsv = []\n",
    "            for i in range(hsv.shape[0]):\n",
    "                pixels_h = np.zeros(hsv.shape[1])\n",
    "                pixels_s = np.zeros(hsv.shape[1])\n",
    "                pixels_v = np.zeros(hsv.shape[1])\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    pixels_h[j] = hsv[i,j][0]\n",
    "                    pixels_s[j] = hsv[i,j][1]\n",
    "                    pixels_v[j] = hsv[i,j][2]\n",
    "                rows_hsv.append([statistics.median(val) for val in [pixels_h, pixels_s, pixels_v]])\n",
    "                #print(rows_hsv)\n",
    "            rows_hsv = np.array(rows_hsv)\n",
    "            strip_hsv = [statistics.median(rows_hsv[:,0]), \n",
    "                               statistics.median(rows_hsv[:,1]),\n",
    "                               statistics.median(rows_hsv[:,2])]\n",
    "            hue_correction = standard_hsv[0]/strip_hsv[0]\n",
    "            sat_correction = standard_hsv[1]/strip_hsv[1]\n",
    "            val_correction = standard_hsv[2]/strip_hsv[2]\n",
    "            for i in range(hsv.shape[0]):\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    # hsv[i,j][0] = min(179, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][0] = min(180, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][1] = hsv[i,j][1] * sat_correction\n",
    "                    hsv[i,j][2] = hsv[i,j][2] * val_correction\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_BGR2RGB\n",
    "\n",
    "        elif correction_method == 'clahe':\n",
    "            clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(10,10))\n",
    "            hew_corrected_norm_strip_images.append(clahe.apply(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB        \n",
    "\n",
    "        elif correction_method == 'he':\n",
    "            hew_corrected_norm_strip_images.append(\n",
    "                cv2.equalizeHist(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        elif correction_method == 'gray':\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        else:\n",
    "            raise Exception('incorrect normalization type')\n",
    "\n",
    "#         plots[idx].imshow(cv2.cvtColor(vimg, vimg_color))\n",
    "    #     plots[idx].imshow(vimg)\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "    peak_values_norm = []\n",
    "    for img in norm_strip_images:\n",
    "        data = img.astype('int32') \n",
    "        pk_idx, pk_val, _ = getPeak(data)\n",
    "        peak_values_norm += [pk_val]\n",
    "\n",
    "    # repeat above for images with corected hue\n",
    "\n",
    "    peak_values_corr = []\n",
    "    for img in hew_corrected_norm_strip_images:\n",
    "        data = img.astype('int32') \n",
    "        pk_idx, pk_val, _ = getPeak(data)\n",
    "        peak_values_corr += [pk_val]   \n",
    "\n",
    "    return peak_values_norm, peak_values_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold with original values\n",
      "threshold: 179.53616737154647\n",
      "mean of control samples: 220.81222222222223\n",
      "sd of control samples: 10.02973212719113\n",
      "sd of low-concentration samples: 15.062094529754612\n",
      "     \n",
      "Threshold with corrected values\n",
      "threshold: 137.91724867395604\n",
      "mean of control samples: 199.44666666666666\n",
      "sd of control samples: 5.742259524302648\n",
      "sd of low-concentration samples: 31.661641991022957\n"
     ]
    }
   ],
   "source": [
    "norm_values_cont, corr_values_cont = getPeakValues(filename_cont)\n",
    "norm_values_lowc, corr_values_lowc = getPeakValues(filename_lowc)\n",
    "\n",
    "print(\"Threshold with original values\")\n",
    "m0 = np.mean(norm_values_cont)\n",
    "sd0 = np.std(norm_values_cont)\n",
    "sd = np.std(norm_values_lowc)\n",
    "lob = m0 - 1.645 * sd0\n",
    "threshold = lob - 1.645 * sd\n",
    "print(\"threshold:\", threshold)\n",
    "print(\"mean of control samples:\", m0)\n",
    "print(\"sd of control samples:\", sd0)\n",
    "print(\"sd of low-concentration samples:\", sd)\n",
    "\n",
    "print(\"     \")\n",
    "\n",
    "print(\"Threshold with corrected values\")\n",
    "m0 = np.mean(corr_values_cont)\n",
    "sd0 = np.std(corr_values_cont)\n",
    "sd = np.std(corr_values_lowc)\n",
    "lob = m0 - 1.645 * sd0\n",
    "threshold = lob - 1.645 * sd\n",
    "print(\"threshold:\", threshold)\n",
    "print(\"mean of control samples:\", m0)\n",
    "print(\"sd of control samples:\", sd0)\n",
    "print(\"sd of low-concentration samples:\", sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
