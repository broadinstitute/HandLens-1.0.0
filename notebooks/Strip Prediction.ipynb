{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import cv2\n",
    "import imutils\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = ['dilution1',\n",
    "              'dilution2',\n",
    "              'dilution3',\n",
    "              'dilution4',\n",
    "              'dilution5']\n",
    "\n",
    "# test_files = ['SL-IV-1',\n",
    "#               'EBOV-1-G2']\n",
    "\n",
    "# #               'EBOV-2-G9', # too dark\n",
    "# #              'SL-LOD-1.jpg', # too dark\n",
    "              \n",
    "#               'LF-1-patients',\n",
    "#               'N2-LOD-1',\n",
    "#               'N2-LOD-2',\n",
    "#               'N2-LOD-3',\n",
    "#               'NG-LOD-1']\n",
    "\n",
    "LODStandardDeviation = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utilities\n",
    "\n",
    "def makeOrderedBox(rect):\n",
    "    \"\"\"\n",
    "    Return a 4-element tuple representing the corners of a box:\n",
    "        idx 0 = top left corner   \n",
    "        idx 1 = top right corner \n",
    "        idx 2 = bottom right corner\n",
    "        idx 3 = botton left corner\n",
    "    \"\"\"\n",
    "    box0 = cv2.boxPoints(rect)\n",
    "    box0 = np.int0(box0)\n",
    "    \n",
    "    xval = [pt[0] for pt in box0]\n",
    "    yval = [pt[1] for pt in box0]\n",
    "    \n",
    "    x0 = np.mean(xval)\n",
    "    y0 = np.mean(yval)\n",
    "  \n",
    "    angles = []\n",
    "    for i in range(0, len(box0)):\n",
    "        xi = box0[i][0]\n",
    "        yi = box0[i][1]        \n",
    "        x = xi - x0\n",
    "        y = yi - y0\n",
    "        a = np.arctan2(y, x)\n",
    "        val = [a, i]\n",
    "        angles += [val]\n",
    "\n",
    "    angles.sort(key=lambda val: val[0], reverse=False)    \n",
    "    box = np.array([box0[val[1]] for val in angles])\n",
    "    \n",
    "    return box\n",
    "\n",
    "def boxMinX(box):\n",
    "    return min([pt[0] for pt in box])\n",
    "\n",
    "def boxMaxX(box):  \n",
    "    return max([pt[0] for pt in box])\n",
    "\n",
    "def boxMinY(box):\n",
    "    return min([pt[1] for pt in box])\n",
    "\n",
    "def boxMaxY(box):\n",
    "    return max([pt[1] for pt in box])\n",
    "\n",
    "def boxArea(box):\n",
    "    x0 = np.mean([pt[0] for pt in box])\n",
    "    y0 = np.mean([pt[1] for pt in box])\n",
    "    p0 = np.array([x0, y0])\n",
    "    \n",
    "    area = 0\n",
    "    n = len(box)\n",
    "    for i in range(0, n):\n",
    "        p1 = box[i]\n",
    "        if i < n - 1:\n",
    "            p2 = box[i + 1]\n",
    "        else:\n",
    "            p2 = box[0]\n",
    "            \n",
    "        # Heron's Formula\n",
    "        a = np.linalg.norm(p1-p0)\n",
    "        b = np.linalg.norm(p2-p0)\n",
    "        c = np.linalg.norm(p1-p2)\n",
    "        s = (a + b + c) / 2\n",
    "        triarea = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "        \n",
    "        area += triarea        \n",
    "        \n",
    "    return area\n",
    "\n",
    "def rectArea(rect):\n",
    "    return rect[1][0]*rect[1][1]\n",
    "\n",
    "def pointDistance(p1, p2):\n",
    "    \"\"\"\n",
    "    Given two poiints, each represented by a tuple (x1, y1), calculate the eucalidian distance\n",
    "    between them.\n",
    "    \"\"\"\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5\n",
    "\n",
    "def boxesIntersection(box1, box2, img_shape):\n",
    "    # Calculate the total intersection area of two boxes:\n",
    "    \n",
    "    # first sort the points in the boxes as (x,y) in descending order:\n",
    "    box1.sort()\n",
    "    box2.sort()\n",
    "    \n",
    "    blanked_image = np.zeros( shape = (img_shape[0], img_shape[1], 1), dtype = \"uint8\")\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    \n",
    "    return cv2.countNonZero(blanked_image)\n",
    "\n",
    "def applyClahetoRGB(bgr_imb):\n",
    "    \n",
    "    lab= cv2.cvtColor(bgr_imb, cv2.COLOR_BGR2LAB)\n",
    "    # Split lab image to different channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    \n",
    "    #Convert image from LAB Color model to RGB model\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return final\n",
    "\n",
    "def intersectLines(pt1, pt2, ptA, ptB): \n",
    "    \"\"\" this returns the intersection of Line(pt1,pt2) and Line(ptA,ptB)\n",
    "        https://www.cs.hmc.edu/ACM/lectures/intersections.html    \n",
    "        \n",
    "        returns a tuple: (xi, yi, valid, r, s), where\n",
    "        (xi, yi) is the intersection\n",
    "        r is the scalar multiple such that (xi,yi) = pt1 + r*(pt2-pt1)\n",
    "        s is the scalar multiple such that (xi,yi) = pt1 + s*(ptB-ptA)\n",
    "            valid == 0 if there are 0 or inf. intersections (invalid)\n",
    "            valid == 1 if it has a unique intersection ON the segment    \"\"\"\n",
    "\n",
    "    DET_TOLERANCE = 0.00000001\n",
    "\n",
    "    # the first line is pt1 + r*(pt2-pt1)\n",
    "    # in component form:\n",
    "    x1, y1 = pt1;   x2, y2 = pt2\n",
    "    dx1 = x2 - x1;  dy1 = y2 - y1\n",
    "\n",
    "    # the second line is ptA + s*(ptB-ptA)\n",
    "    x, y = ptA;   xB, yB = ptB;\n",
    "    dx = xB - x;  dy = yB - y;\n",
    "\n",
    "    # we need to find the (typically unique) values of r and s\n",
    "    # that will satisfy\n",
    "    #\n",
    "    # (x1, y1) + r(dx1, dy1) = (x, y) + s(dx, dy)\n",
    "    #\n",
    "    # which is the same as\n",
    "    #\n",
    "    #    [ dx1  -dx ][ r ] = [ x-x1 ]\n",
    "    #    [ dy1  -dy ][ s ] = [ y-y1 ]\n",
    "    #\n",
    "    # whose solution is\n",
    "    #\n",
    "    #    [ r ] = _1_  [  -dy   dx ] [ x-x1 ]\n",
    "    #    [ s ] = DET  [ -dy1  dx1 ] [ y-y1 ]\n",
    "    #\n",
    "    # where DET = (-dx1 * dy + dy1 * dx)\n",
    "    #\n",
    "    # if DET is too small, they're parallel\n",
    "    #\n",
    "    DET = (-dx1 * dy + dy1 * dx)\n",
    "\n",
    "    if math.fabs(DET) < DET_TOLERANCE: return (0,0,0,0,0)\n",
    "\n",
    "    # now, the determinant should be OK\n",
    "    DETinv = 1.0/DET\n",
    "\n",
    "    # find the scalar amount along the \"self\" segment\n",
    "    r = DETinv * (-dy  * (x-x1) +  dx * (y-y1))\n",
    "\n",
    "    # find the scalar amount along the input line\n",
    "    s = DETinv * (-dy1 * (x-x1) + dx1 * (y-y1))\n",
    "\n",
    "    # return the average of the two descriptions\n",
    "    xi = (x1 + r*dx1 + x + s*dx)/2.0\n",
    "    yi = (y1 + r*dy1 + y + s*dy)/2.0\n",
    "    return ( xi, yi, 1, r, s )\n",
    "\n",
    "def line(p1, p2):\n",
    "    A = (p1[1] - p2[1])\n",
    "    B = (p2[0] - p1[0])\n",
    "    C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "    return A, B, -C\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return x,y\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def rotate_image(img, center, angle, width, height):\n",
    "\n",
    "   shape = (img.shape[1], img.shape[0]) # (length, height)\n",
    "\n",
    "   matrix = cv2.getRotationMatrix2D((center[0], center[1]), angle, 1 )\n",
    "   rotated = cv2.warpAffine( img, matrix, shape )\n",
    "\n",
    "   x = int( center[0] - width/2  )\n",
    "   y = int( center[1] - height/2 )\n",
    "\n",
    "   cropped = rotated[ y:y+height, x:x+width ]\n",
    "\n",
    "   return cropped\n",
    "\n",
    "def getTruthValueFromFile(filename):\n",
    "    if filename is None:\n",
    "        return []\n",
    "    truth_values = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line != 'pos' and line != 'neg':\n",
    "                raise Exception('Truth file contains line other than \"pos\" or \"neg\"')\n",
    "            if line == 'pos':                    \n",
    "                truth_values.append(1)\n",
    "            else:\n",
    "                truth_values.append(0)\n",
    "    return truth_values\n",
    "\n",
    "def score_confidence_interval(score_fun, y_true, y_pred, pvalue, niter):\n",
    "    \"\"\"\n",
    "    Calculation of the confidence interval for a given p-value using bootstrap sampling\n",
    "    http://stackoverflow.com/questions/19124239/scikit-learn-roc-curve-with-confidence-intervals\n",
    "    \"\"\"\n",
    "    \n",
    "    n_bootstraps = niter\n",
    "    bootstrapped_scores = []\n",
    "    \n",
    "#     rng_seed = 42  # control reproducibility\n",
    "#     rng = np.random.RandomState(rng_seed)\n",
    "\n",
    "    rng = np.random.RandomState()\n",
    "    for i in range(n_bootstraps):\n",
    "        # bootstrap by sampling with replacement on the prediction indices\n",
    "        indices = rng.randint(0, len(y_pred) - 1, len(y_pred))\n",
    "        \n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            # We need at least one positive and one negative sample for ROC AUC\n",
    "            # to be defined: reject the sample\n",
    "            continue\n",
    "\n",
    "        score = score_fun(y_true[indices], y_pred[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "    \n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "\n",
    "    confidence_lower = sorted_scores[int((1 - pvalue) * len(sorted_scores))] \n",
    "    confidence_upper = sorted_scores[int(pvalue * len(sorted_scores))]\n",
    "\n",
    "    return [confidence_lower, confidence_upper]\n",
    "\n",
    "def auc_confidence_interval(y_true, y_pred, pvalue=0.95, niter=1000):\n",
    "    return score_confidence_interval(roc_auc_score, y_true, y_pred, pvalue, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual detection code, all in a single function:\n",
    "\n",
    "def getmin(data):\n",
    "    half = int(data.shape[0]/2)\n",
    "    top = data.shape[0]\n",
    "    values = np.array([])\n",
    "    for i in range(half, top):\n",
    "        values = np.append(values, np.mean(data[i]))\n",
    "    m = np.min(values)\n",
    "    sd = np.std(values)\n",
    "    return m, sd\n",
    "\n",
    "def predict(data, mint, maxt):\n",
    "    m, sd = getmin(data)\n",
    "    f = (m - mint) / (maxt - mint)\n",
    "    if f < 0: f = 0\n",
    "    if 1 < f: f = 1\n",
    "    score = 1 - f\n",
    "    return score\n",
    "\n",
    "def getPredictions(filename):\n",
    "    # The maximum and minimum allowed ratios of the sides of the green box\n",
    "    maxGreenBoxRatio = 140.0/528\n",
    "    minGreenBoxRatio = 102.0/578\n",
    "\n",
    "    # The maximum allowed ratio of the sides of the final deteted strip\n",
    "    maxStripBoxRatio = 70/480\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the sides of the box defined by the red arrows\n",
    "    maxRedBoxRatio = 42.0/91\n",
    "    minRedBoxRatio = 14.0/104\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the areas of green boxes and red arrow-bounding boxes\n",
    "    maxRedGreenBoxRatio = 3500.0/4000\n",
    "    minRedGreenBoxRatio = 2000.0/4500\n",
    "    # minRedGreenIntersection = 1000.0/4500\n",
    "\n",
    "    # Minimum intensity for binary thresholding of the top portion of the strips\n",
    "    minStripThreshold = 190\n",
    "\n",
    "    # Sensitive area of the strip\n",
    "    stripWidth = 200\n",
    "    stripHeight = 2000\n",
    "    stripHoldY = 900\n",
    "    # maxPeakAlign = 50\n",
    "\n",
    "    # Percentage of the margins to be removed\n",
    "    marginFraction = 0.2\n",
    "\n",
    "    # Red is at the beginning/end of the hue range, so it covers the [0-15] and the [170, 180] \n",
    "    # (hue in OpenCV varies  between 0 and 180 degrees)\n",
    "    lower_red1 = np.array([0, 50, 50]) \n",
    "    upper_red1 = np.array([13, 255, 255])\n",
    "    lower_red2 = np.array([170, 50, 50]) \n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Green is between 20 and 90 (these ranges can be adjusted)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "\n",
    "    # We can also use a large color range to encapsulate both red and green:\n",
    "    lower_redgreen1 = np.array([0, 50, 50]) \n",
    "    upper_redgreen1 = np.array([83, 255, 255])\n",
    "    lower_redgreen2 = np.array([170, 50, 50]) \n",
    "    upper_redgreen2 = np.array([180, 255, 255])    \n",
    "    \n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    \n",
    "    # Processing Step 1: detecting the colored area in the strips\n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    # First, use CLAHE to improve image quality:\n",
    "    # plt.subplot(2, 1, 1)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # image = applyClahetoRGB(image)\n",
    "    # plt.subplot(2, 1, 2)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # First, convert the image to HSV color space, which makes the color detection straightforward\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # These strips have red arrows on a green background, so we define two masks, one for red and the other for green\n",
    "\n",
    "    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1) \n",
    "    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2) \n",
    "\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    red_mask = red_mask1 + red_mask2\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    redgreen_mask1 = cv2.inRange(hsv, lower_redgreen1, upper_redgreen1) \n",
    "    redgreen_mask2 = cv2.inRange(hsv, lower_redgreen2, upper_redgreen2) \n",
    "    mask = redgreen_mask1 + redgreen_mask2\n",
    "      \n",
    "    # Processing Step 2a: determining the bounding boxes for the red arrows.\n",
    "    # Because the red hue seems to be well-conserved between images,\n",
    "    # we have a high confidence of putting a box around all the red arrows. \n",
    "    cnts = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    red_boxes = []\n",
    "    red_rectangles = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( top-left corner(x,y),  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        redBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if redBoxRatio < minRedBoxRatio or maxRedBoxRatio < redBoxRatio: continue\n",
    "        red_boxes += [box[0:]]\n",
    "        red_rectangles += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 3, (255,0,0), -1)    \n",
    "    \n",
    "    # Processing Step 2b: finding green box candidates\n",
    "    # Stage 1:\n",
    "    #     Given a masked version of the image which includes red to green hues,\n",
    "    #     find all green contours\n",
    "    # Stage 2:\n",
    "    #     Declare a green contour to be a green_rect_candidate to be further \n",
    "    #     analyzed if the ratio of the sides of the contour are similar to that\n",
    "    #     observed in the Sherlock strips. \n",
    "    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    green_box_candidates = []\n",
    "    green_rect_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( (x,y) of middle of top side of rect,  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        greenBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if greenBoxRatio < minGreenBoxRatio or maxGreenBoxRatio < greenBoxRatio: continue\n",
    "\n",
    "        area = boxArea(box)\n",
    "        green_box_candidates += [box[0:]]\n",
    "        green_rect_candidates += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 2c: filter the green_box_candidates based on size (imputed from\n",
    "    # the red box areas) and shape (ratio of lengths of the sides).\n",
    "    # Stage 1:\n",
    "    #     Mark all candidate green boxes which are within a particular size range\n",
    "    #     of a red box. Because we can put bounding boxes around red arrows with a \n",
    "    #     high confidence, and there is little-to-no red hue in the source image \n",
    "    #     excluding the red arrows, we can impute that the largest of these marked\n",
    "    #     are the green boxes around the arrows (the contrary would suggest a large\n",
    "    #     green spot in the source image, or some severe hue errors)\n",
    "    # Stage 2:\n",
    "    #     Sort the marked boxes by size; chose the second largest marked box as a\n",
    "    #     representative green box\n",
    "    # Stage 3:\n",
    "    #     Filter out marked green boxes which are not a similar size as the\n",
    "    #     representative green box.\n",
    "\n",
    "    green_boxes = {}\n",
    "    green_rects = {}\n",
    "    for i, red_box in enumerate(red_boxes):\n",
    "        red_box_area = boxArea(red_box)*1.0\n",
    "        for j, green_box in enumerate(green_box_candidates):\n",
    "            green_box_area = boxArea(green_box)*1.0\n",
    "            redGreenBoxRatio = red_box_area/green_box_area\n",
    "            if minRedGreenBoxRatio < redGreenBoxRatio < maxRedGreenBoxRatio:\n",
    "                # now check for intersections:\n",
    "                green_boxes[j] = True\n",
    "                green_rects[j] = True\n",
    "\n",
    "    green_boxes = [green_box_candidates[j] for j in green_boxes]\n",
    "    green_rects = [green_rect_candidates[j] for j in green_rects]\n",
    "    green_boxes.sort(key = lambda box : boxArea(box), reverse=True)\n",
    "    green_rects.sort(key = lambda rect : rectArea(rect), reverse=True)\n",
    "\n",
    "    if len(green_rects) < 2:\n",
    "        raise Exception('Not enough strips')\n",
    "    if rectArea(green_rects[0]) < 1.25* rectArea(green_rects[1]):\n",
    "        greenBoxArea = rectArea(green_rects[1])\n",
    "        green_rect_len = max(green_rects[1][1][0], green_rects[1][1][1])\n",
    "    elif len(green_boxes) < 3 \\\n",
    "            and rectArea(green_rects[1]) < 1.25* rectArea(green_rects[2]):\n",
    "        greenBoxArea = rectArea(green_rects[2])\n",
    "        green_rect_len = max(green_rects[2][1][0], green_rects[2][1][1])\n",
    "    else:\n",
    "        raise Exception('Too much noise in image')\n",
    "\n",
    "    center_boxes = [box for box in green_boxes \n",
    "                     if 0.8*greenBoxArea < boxArea(box) < 1.25*greenBoxArea]\n",
    "    greenBoxArea = statistics.median([boxArea(box) for box in center_boxes])\n",
    "\n",
    "    # Processing Step 3: binary thresholding of the entire image to extract the top part of the strips\n",
    "    ret, thresh = cv2.threshold(image, minStripThreshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Processing Step 4: detect boundary boxes for the top of the strips\n",
    "    grayscale = cv2.cvtColor(thresh, cv2.COLOR_BGR2GRAY)\n",
    "    cnts = cv2.findContours(grayscale, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    # Minimum area of the top strip boxes\n",
    "    minTopBoxArea = 1.8 * greenBoxArea\n",
    "    # Maximum of the top strip boxes\n",
    "    maxTopBoxArea = 5 * greenBoxArea\n",
    "\n",
    "    top_box_candidates = []\n",
    "    top_rects_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        area = boxArea(box)\n",
    "        if area < minTopBoxArea/15 or maxTopBoxArea < area: \n",
    "            continue\n",
    "\n",
    "        top_box_candidates += [box]\n",
    "        top_rects_candidates += [rect]\n",
    "    \n",
    "    # In some cases, the strip signal is so strong that a continuous box gets split up into two boxes. \n",
    "    # We fix this by merging two boxes if the bottom left and top left corners of the respective boxes,\n",
    "    # and the  right and top right corners of the respective boxes are within a threshold distance of\n",
    "    # # each other. \n",
    "    top_boxes = []\n",
    "    top_box_candidates.sort(key = lambda item : item[1][1])\n",
    "    distance_threshold = green_rect_len * 0.15\n",
    "    merged_boxes = {}\n",
    "    tmp = image.copy()\n",
    "    for i in range(0, len(top_box_candidates)):\n",
    "        upper_box = top_box_candidates[i]\n",
    "        if i in merged_boxes:\n",
    "            continue\n",
    "        current_merged_upper_box = upper_box\n",
    "        for j in range(i, len(top_box_candidates)):\n",
    "            lower_box = top_box_candidates[j]\n",
    "            if pointDistance(current_merged_upper_box[3], lower_box[0]) < distance_threshold and \\\n",
    "                    pointDistance(current_merged_upper_box[2], lower_box[1]) < distance_threshold:\n",
    "                # Sometimes the arrows get detected in this step as false boxes -- to filter for this, \n",
    "                # we make sure that boxes can only be concatenated if they have similar width:\n",
    "                if pointDistance(current_merged_upper_box[3], current_merged_upper_box[2]) < \\\n",
    "                        pointDistance(lower_box[0], lower_box[1])*1.5:\n",
    "                    current_merged_upper_box = np.array([current_merged_upper_box[0], \n",
    "                                                         current_merged_upper_box[1], \n",
    "                                                         lower_box[2], lower_box[3]])\n",
    "\n",
    "                    if minTopBoxArea < boxArea(current_merged_upper_box): \n",
    "                        merged_boxes[j] =  True\n",
    "        else:\n",
    "            stripBoxRatio = pointDistance(current_merged_upper_box[0], \n",
    "                                          current_merged_upper_box[1])/ \\\n",
    "                                          pointDistance(current_merged_upper_box[0],\n",
    "                                                        current_merged_upper_box[3])\n",
    "            if minTopBoxArea < boxArea(current_merged_upper_box) and \\\n",
    "                    stripBoxRatio < maxStripBoxRatio: \n",
    "                top_boxes.append(current_merged_upper_box) \n",
    "\n",
    "    for box in top_boxes:\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 5)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 5: construct the boxes that enclose the sensitive strip area\n",
    "    # First, order the top boxes from left to right\n",
    "    top_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "    # Find the red boxes which bound arrows, and then\n",
    "    # order them left to right\n",
    "    red_boxes.sort(key=lambda box: boxArea(box), reverse=True)\n",
    "    red_boxes = red_boxes[0:len(top_boxes)]\n",
    "    red_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "    num_boxes = len(top_boxes)\n",
    "    strip_boxes = []\n",
    "    for i in range(0, num_boxes):\n",
    "        tbox = top_boxes[i]\n",
    "        rbox = red_boxes[i]    \n",
    "\n",
    "        # The corners are expected to be received in the following order:\n",
    "        # 0 = botton left corner\n",
    "        # 1 = top left corner   \n",
    "        # 2 = top right corner \n",
    "        # 3 = bottom right corner\n",
    "\n",
    "        tp0, tp1, tp2, tp3 = tbox[3], tbox[0], tbox[1], tbox[2]\n",
    "        rp0, rp1, rp2, rp3 = rbox[3], rbox[0], rbox[1], rbox[2]\n",
    "\n",
    "        # The intersection of the lines defining the sides of the strip (tp1-tp0 and tp2-tp3)\n",
    "        # with the bottom edge of the red box defines the bottom corners of the area of interest\n",
    "        res1 = intersection(line(tp1, tp0), line(rp0, rp3))\n",
    "        res2 = intersection(line(tp2, tp3), line(rp0, rp3)) \n",
    "\n",
    "        assert(res1 != False and res2 != False), \"Top and center boxes are not intersecting\"\n",
    "\n",
    "        p1 = np.array([int(round(res1[0])), int(round(res1[1]))])\n",
    "        p2 = np.array([int(round(res2[0])), int(round(res2[1]))])\n",
    "\n",
    "        sbox = np.array([p1, tp1, tp2, p2])\n",
    "        strip_boxes += [sbox]\n",
    "    \n",
    "    # Processing Step 6: Extract the strips into separate images\n",
    "    ref_box = np.array([[0, 0],[0, stripHeight],[stripWidth, stripHeight],[stripWidth, 0]], dtype=float)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "#     fig, plots = plt.subplots(1, len(strip_boxes)*3, figsize=(10, 10))\n",
    "    idx = 0\n",
    "    tmp = image.copy()\n",
    "    raw_strip_images = []\n",
    "    for sbx in strip_boxes:\n",
    "        center = (statistics.mean([sbx[0][0], sbx[1][0], sbx[2][0], sbx[3][0]]),\n",
    "                  statistics.mean([sbx[0][1], sbx[1][1], sbx[2][1], sbx[3][1]]))\n",
    "        angle = -1*np.degrees(np.arctan2(sbx[0][0]-sbx[1][0], sbx[0][1] - sbx[1][1]))\n",
    "        #angle = angle if sbx[0][0] < sbx[1][0] else angle*-1\n",
    "        width = int(pointDistance(sbx[1], sbx[2]))\n",
    "        height = int(pointDistance(sbx[0], sbx[1]))\n",
    "#         print(angle)\n",
    "#         print(width)\n",
    "        straigtened_strip = rotate_image(image, center, angle, width, \n",
    "                                                    height)\n",
    "        # Spurious hits often occur at the edges of the strip, so let's\n",
    "        # crop them away\n",
    "        cropped_strip = straigtened_strip[:, \n",
    "                                          int(straigtened_strip.shape[1]*0.1):\n",
    "                                          int(straigtened_strip.shape[1]*0.9)]\n",
    "\n",
    "#         plots[idx].imshow(cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        hsv = cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2HSV)\n",
    "        green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        cnts = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        # Create a copy of the image to draw the bounding boxes on\n",
    "        tmp = cropped_strip.copy()\n",
    "        colored_box_cutoff = tmp.shape[0]\n",
    "        for c in cnts:\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0: continue\n",
    "\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = makeOrderedBox(rect)\n",
    "            if boxArea(box) > 0.10*greenBoxArea:\n",
    "                if box[0][1] < colored_box_cutoff:\n",
    "                    colored_box_cutoff = box[0][1]\n",
    "            tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "            tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 10, (255,0,0), -1)\n",
    "        #plots[idx + 0].imshow(cv2.cvtColor(green_mask, cv2.COLOR_BGR2RGB))\n",
    "#         plots[idx + 0].imshow(cv2.cvtColor(tmp, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        colored_box_cutoff = colored_box_cutoff\n",
    "        final_strip = straigtened_strip[0:colored_box_cutoff, :]\n",
    "#         plots[idx + 1].imshow(cv2.cvtColor(final_strip, cv2.COLOR_BGR2RGB))\n",
    "    #     h, status = cv2.findHomography(final_strip, ref_box)\n",
    "    #     img = cv2.warpPerspective(image, h, (stripWidth, stripHeight))\n",
    "    #     raw_strip_images += [img]\n",
    "        height = final_strip.shape[0]\n",
    "        width = final_strip.shape[1]\n",
    "        h, status = cv2.findHomography(np.array([(0,height), (0,0), (width, 0), (width, height)]), ref_box)\n",
    "        img = cv2.warpPerspective(final_strip, h, (stripWidth, stripHeight))\n",
    "        raw_strip_images += [img]\n",
    "#         plots[idx + 2].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        idx += 3    \n",
    "    \n",
    "    # Processing Step 7: Crop the images to remove the grip of the strips, and the vertical borders\n",
    "    norm_strip_images = []\n",
    "#     fig, plots = plt.subplots(1, len(raw_strip_images), figsize=(10, 10))\n",
    "    idx = 0\n",
    "    for img in raw_strip_images:\n",
    "        # Crop out the top and the bottom parts of the strip, and applying bilateral filtering for smoothing\n",
    "        # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
    "        x0 = int(marginFraction * stripWidth)\n",
    "        x1 = int((1 - marginFraction) * stripWidth)\n",
    "        y0 = 0\n",
    "        y1 = stripHoldY\n",
    "\n",
    "        crop = img[y0:y1, x0:x1]\n",
    "        nimg = cv2.bilateralFilter(crop, 9, 75, 75)\n",
    "        nimg = nimg[30:, :]\n",
    "        norm_strip_images += [nimg]\n",
    "\n",
    "        vimg = cv2.flip(nimg, 0)\n",
    "#         if idx == 1: plots[idx].axis('off')\n",
    "#         plots[idx].imshow(cv2.cvtColor(vimg, cv2.COLOR_BGR2RGB))\n",
    "        idx += 1    \n",
    "    \n",
    "    # Processing Step 7b: Normalize HSV values\n",
    "    correction_method = 'clahe' # {'linear', 'clahe', 'gray', 'he'}\n",
    "    idx = 0\n",
    "    hew_corrected_norm_strip_images = []\n",
    "    for nimg in norm_strip_images:\n",
    "        hsv = cv2.cvtColor(nimg, cv2.COLOR_BGR2HSV)\n",
    "        # determine the hsv color of this strip\n",
    "        if correction_method == 'linear':\n",
    "            # We chose a standard hsv value to normalize all of our images to:\n",
    "            standard_hsv = [16.0/1.5, 17.0/1.5, 243.0/1.5]\n",
    "            # standard_hsv = [16.0, 17.0, 243.0]\n",
    "\n",
    "            rows_hsv = []\n",
    "            for i in range(hsv.shape[0]):\n",
    "                pixels_h = np.zeros(hsv.shape[1])\n",
    "                pixels_s = np.zeros(hsv.shape[1])\n",
    "                pixels_v = np.zeros(hsv.shape[1])\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    pixels_h[j] = hsv[i,j][0]\n",
    "                    pixels_s[j] = hsv[i,j][1]\n",
    "                    pixels_v[j] = hsv[i,j][2]\n",
    "                rows_hsv.append([statistics.median(val) for val in [pixels_h, pixels_s, pixels_v]])\n",
    "                #print(rows_hsv)\n",
    "            rows_hsv = np.array(rows_hsv)\n",
    "            strip_hsv = [statistics.median(rows_hsv[:,0]), \n",
    "                               statistics.median(rows_hsv[:,1]),\n",
    "                               statistics.median(rows_hsv[:,2])]\n",
    "            hue_correction = standard_hsv[0]/strip_hsv[0]\n",
    "            sat_correction = standard_hsv[1]/strip_hsv[1]\n",
    "            val_correction = standard_hsv[2]/strip_hsv[2]\n",
    "            for i in range(hsv.shape[0]):\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    # hsv[i,j][0] = min(179, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][0] = min(180, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][1] = hsv[i,j][1] * sat_correction\n",
    "                    hsv[i,j][2] = hsv[i,j][2] * val_correction\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_BGR2RGB\n",
    "\n",
    "        elif correction_method == 'clahe':\n",
    "            clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(10,10))\n",
    "            hew_corrected_norm_strip_images.append(clahe.apply(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB        \n",
    "\n",
    "        elif correction_method == 'he':\n",
    "            hew_corrected_norm_strip_images.append(\n",
    "                cv2.equalizeHist(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        elif correction_method == 'gray':\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        else:\n",
    "            raise Exception('incorrect normalization type')\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "    # Processing Step 8: make prediction\n",
    "    idx = len(norm_strip_images) - 1\n",
    "    min0 = 0\n",
    "    img0 = hew_corrected_norm_strip_images[idx]\n",
    "    data0 = img0.astype('int32')\n",
    "    min0, _ = getmin(data0)\n",
    "    mint = min0 - LODStandardDeviation\n",
    "    maxt = min0 + LODStandardDeviation\n",
    "\n",
    "    preds = []\n",
    "    for img in hew_corrected_norm_strip_images:\n",
    "        data = img.astype('int32') \n",
    "        nrows = data.shape[0]\n",
    "        if not idx == 0:\n",
    "            pred = predict(data, mint, maxt)\n",
    "#             print(pred)\n",
    "            preds += [pred]\n",
    "        idx -= 1\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/dilution1.jpg\n",
      "[1, 1, 1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 1, 1, 0.6428763440860212]\n",
      "images/dilution2.jpg\n",
      "[1, 1, 1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 1, 1, 0.45779569892473104]\n",
      "images/dilution3.jpg\n",
      "[1, 1, 1, 1, 1, 0, 0]\n",
      "[1, 1, 0.7982526881720431, 0.700940860215054, 0.6204301075268818, 0.6788978494623656]\n",
      "images/dilution4.jpg\n",
      "[1, 1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0.5126344086021505, 0.5103494623655915]\n",
      "images/dilution5.jpg\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0.6764784946236558]\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "all_truths = []\n",
    "for test in test_files:\n",
    "    img_fn = 'images/' + test + \".jpg\"\n",
    "    tru_fn = 'images/' + test + \".txt\"\n",
    "\n",
    "    t = getTruthValueFromFile(tru_fn)\n",
    "    s = getPredictions(img_fn)\n",
    "    all_scores += s\n",
    "    all_truths += t[:-1]\n",
    "    print(img_fn)\n",
    "    print(t)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strips   : 27\n",
      "Number of positives: 22\n",
      "Perc. of positives : 81.48\n",
      "\n",
      "Measures of performance\n",
      "AUC           : 0.95 (0.88, 1.00)\n",
      "Brier         : 0.09\n",
      "Accuracy      : 0.93\n",
      "Sensitivity   : 0.91\n",
      "Specificity   : 1.00\n"
     ]
    }
   ],
   "source": [
    "class_threshold = 0.7\n",
    "p_value = 0.95\n",
    "all_preds = np.array([int(class_threshold < p) for p in all_scores])\n",
    "\n",
    "ytrue = np.array(all_truths)\n",
    "probs = np.array(all_scores)\n",
    "ypred = all_preds\n",
    "\n",
    "auc = roc_auc_score(ytrue, probs)\n",
    "fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "brier = brier_score_loss(ytrue, probs)\n",
    "# cal, dis = caldis(ytrue, probs)\n",
    "acc = accuracy_score(ytrue, ypred)\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(ytrue, ypred)\n",
    "\n",
    "auc_ci = auc_confidence_interval(ytrue, probs, p_value)\n",
    "\n",
    "P = N = 0\n",
    "TP = TN = 0\n",
    "FP = FN = 0\n",
    "for i in range(len(ytrue)):\n",
    "    if ytrue[i] == 1:\n",
    "        P += 1\n",
    "        if ypred[i] == 1: TP += 1\n",
    "        else: FN += 1\n",
    "    else:\n",
    "        N += 1\n",
    "        if ypred[i] == 0: TN += 1\n",
    "        else: FP += 1\n",
    "            \n",
    "sens = float(TP)/P\n",
    "spec = float(TN)/N\n",
    "\n",
    "# Positive and Negative Predictive Values\n",
    "# https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values\n",
    "ppv = float(TP) / (TP + FP)\n",
    "npv = float(TN) / (TN + FN)\n",
    "        \n",
    "# Likelihood ratios\n",
    "# https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing\n",
    "lr_pos = sens / (1 - spec) if spec < 1 else np.inf\n",
    "lr_neg = (1 - sens) / spec if 0 < spec else np.inf\n",
    "\n",
    "# print \"True outcomes:\", ytrue\n",
    "# print \"Prediction   :\", ypred\n",
    "cfr = 100 * (float(np.sum(ytrue)) / len(ytrue))\n",
    "print(\"Number of strips   :\", len(ytrue))\n",
    "print(\"Number of positives:\", np.sum(ytrue)) \n",
    "print(\"Perc. of positives : %0.2f\" % cfr)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Measures of performance\") \n",
    "print(\"AUC           : %0.2f (%0.2f, %0.2f)\" % (auc, auc_ci[0], auc_ci[1])) \n",
    "print(\"Brier         : %0.2f\" % brier) \n",
    "# print(\"Calibration   :\", cal) \n",
    "# print(\"Discrimination:\", dis) \n",
    "print(\"Accuracy      : %0.2f\" % acc) \n",
    "print(\"Sensitivity   : %0.2f\" % sens) \n",
    "print(\"Specificity   : %0.2f\" % spec) \n",
    "# print(\"PPV           : %0.2f\" % ppv) \n",
    "# print(\"NPV           : %0.2f\" % npv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.plot([0, 1], [0, 1], 'k--', c='grey')\n",
    "plt.plot(fpr, tpr, color='black')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "fig.savefig('reader-roc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
