{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import cv2\n",
    "import imutils\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from scripts import strip_detection\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [\n",
    "               'VHF/dilution1',\n",
    "               'VHF/dilution2',    \n",
    "               'VHF/dilution3',\n",
    "               'VHF/dilution4',\n",
    "               'VHF/dilution5',\n",
    "               'VHF/dilution6',\n",
    "             ]\n",
    "\n",
    "# test_files = ['tickborne/Ana_DNA_LF',\n",
    "#               'tickborne/Ana_FTA_LF',\n",
    "#               'tickborne/Bab_DNA_LF',\n",
    "#               'tickborne/Bab_FTA_LF']\n",
    "\n",
    "# test_files = ['SL-IV-1',\n",
    "#               'EBOV-1-G2']\n",
    "\n",
    "# #               'EBOV-2-G9', # too dark\n",
    "# #              'SL-LOD-1.jpg', # too dark\n",
    "              \n",
    "#               'LF-1-patients',\n",
    "#               'N2-LOD-1',\n",
    "#               'N2-LOD-2',\n",
    "#               'N2-LOD-3',\n",
    "#               'NG-LOD-1']\n",
    "\n",
    "LODStandardDeviation = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utilities\n",
    "\n",
    "def makeOrderedBox(rect):\n",
    "    \"\"\"\n",
    "    Return a 4-element tuple representing the corners of a box:\n",
    "        idx 0 = top left corner   \n",
    "        idx 1 = top right corner \n",
    "        idx 2 = bottom right corner\n",
    "        idx 3 = botton left corner\n",
    "    \"\"\"\n",
    "    box0 = cv2.boxPoints(rect)\n",
    "    box0 = np.int0(box0)\n",
    "    \n",
    "    xval = [pt[0] for pt in box0]\n",
    "    yval = [pt[1] for pt in box0]\n",
    "    \n",
    "    x0 = np.mean(xval)\n",
    "    y0 = np.mean(yval)\n",
    "  \n",
    "    angles = []\n",
    "    for i in range(0, len(box0)):\n",
    "        xi = box0[i][0]\n",
    "        yi = box0[i][1]        \n",
    "        x = xi - x0\n",
    "        y = yi - y0\n",
    "        a = np.arctan2(y, x)\n",
    "        val = [a, i]\n",
    "        angles += [val]\n",
    "\n",
    "    angles.sort(key=lambda val: val[0], reverse=False)    \n",
    "    box = np.array([box0[val[1]] for val in angles])\n",
    "    \n",
    "    return box\n",
    "\n",
    "def boxMinX(box):\n",
    "    return min([pt[0] for pt in box])\n",
    "\n",
    "def boxMaxX(box):  \n",
    "    return max([pt[0] for pt in box])\n",
    "\n",
    "def boxMinY(box):\n",
    "    return min([pt[1] for pt in box])\n",
    "\n",
    "def boxMaxY(box):\n",
    "    return max([pt[1] for pt in box])\n",
    "\n",
    "def boxArea(box):\n",
    "    x0 = np.mean([pt[0] for pt in box])\n",
    "    y0 = np.mean([pt[1] for pt in box])\n",
    "    p0 = np.array([x0, y0])\n",
    "    \n",
    "    area = 0\n",
    "    n = len(box)\n",
    "    for i in range(0, n):\n",
    "        p1 = box[i]\n",
    "        if i < n - 1:\n",
    "            p2 = box[i + 1]\n",
    "        else:\n",
    "            p2 = box[0]\n",
    "            \n",
    "        # Heron's Formula\n",
    "        a = np.linalg.norm(p1-p0)\n",
    "        b = np.linalg.norm(p2-p0)\n",
    "        c = np.linalg.norm(p1-p2)\n",
    "        s = (a + b + c) / 2\n",
    "        triarea = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "        \n",
    "        area += triarea        \n",
    "        \n",
    "    return area\n",
    "\n",
    "def rectArea(rect):\n",
    "    return rect[1][0]*rect[1][1]\n",
    "\n",
    "def pointDistance(p1, p2):\n",
    "    \"\"\"\n",
    "    Given two poiints, each represented by a tuple (x1, y1), calculate the eucalidian distance\n",
    "    between them.\n",
    "    \"\"\"\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5\n",
    "\n",
    "def boxesIntersection(box1, box2, img_shape):\n",
    "    # Calculate the total intersection area of two boxes:\n",
    "    \n",
    "    # first sort the points in the boxes as (x,y) in descending order:\n",
    "    box1.sort()\n",
    "    box2.sort()\n",
    "    \n",
    "    blanked_image = np.zeros( shape = (img_shape[0], img_shape[1], 1), dtype = \"uint8\")\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    \n",
    "    return cv2.countNonZero(blanked_image)\n",
    "\n",
    "def applyClahetoRGB(bgr_imb):\n",
    "    \n",
    "    lab= cv2.cvtColor(bgr_imb, cv2.COLOR_BGR2LAB)\n",
    "    # Split lab image to different channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    \n",
    "    #Convert image from LAB Color model to RGB model\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return final\n",
    "\n",
    "def intersectLines(pt1, pt2, ptA, ptB): \n",
    "    \"\"\" this returns the intersection of Line(pt1,pt2) and Line(ptA,ptB)\n",
    "        https://www.cs.hmc.edu/ACM/lectures/intersections.html    \n",
    "        \n",
    "        returns a tuple: (xi, yi, valid, r, s), where\n",
    "        (xi, yi) is the intersection\n",
    "        r is the scalar multiple such that (xi,yi) = pt1 + r*(pt2-pt1)\n",
    "        s is the scalar multiple such that (xi,yi) = pt1 + s*(ptB-ptA)\n",
    "            valid == 0 if there are 0 or inf. intersections (invalid)\n",
    "            valid == 1 if it has a unique intersection ON the segment    \"\"\"\n",
    "\n",
    "    DET_TOLERANCE = 0.00000001\n",
    "\n",
    "    # the first line is pt1 + r*(pt2-pt1)\n",
    "    # in component form:\n",
    "    x1, y1 = pt1;   x2, y2 = pt2\n",
    "    dx1 = x2 - x1;  dy1 = y2 - y1\n",
    "\n",
    "    # the second line is ptA + s*(ptB-ptA)\n",
    "    x, y = ptA;   xB, yB = ptB;\n",
    "    dx = xB - x;  dy = yB - y;\n",
    "\n",
    "    # we need to find the (typically unique) values of r and s\n",
    "    # that will satisfy\n",
    "    #\n",
    "    # (x1, y1) + r(dx1, dy1) = (x, y) + s(dx, dy)\n",
    "    #\n",
    "    # which is the same as\n",
    "    #\n",
    "    #    [ dx1  -dx ][ r ] = [ x-x1 ]\n",
    "    #    [ dy1  -dy ][ s ] = [ y-y1 ]\n",
    "    #\n",
    "    # whose solution is\n",
    "    #\n",
    "    #    [ r ] = _1_  [  -dy   dx ] [ x-x1 ]\n",
    "    #    [ s ] = DET  [ -dy1  dx1 ] [ y-y1 ]\n",
    "    #\n",
    "    # where DET = (-dx1 * dy + dy1 * dx)\n",
    "    #\n",
    "    # if DET is too small, they're parallel\n",
    "    #\n",
    "    DET = (-dx1 * dy + dy1 * dx)\n",
    "\n",
    "    if math.fabs(DET) < DET_TOLERANCE: return (0,0,0,0,0)\n",
    "\n",
    "    # now, the determinant should be OK\n",
    "    DETinv = 1.0/DET\n",
    "\n",
    "    # find the scalar amount along the \"self\" segment\n",
    "    r = DETinv * (-dy  * (x-x1) +  dx * (y-y1))\n",
    "\n",
    "    # find the scalar amount along the input line\n",
    "    s = DETinv * (-dy1 * (x-x1) + dx1 * (y-y1))\n",
    "\n",
    "    # return the average of the two descriptions\n",
    "    xi = (x1 + r*dx1 + x + s*dx)/2.0\n",
    "    yi = (y1 + r*dy1 + y + s*dy)/2.0\n",
    "    return ( xi, yi, 1, r, s )\n",
    "\n",
    "def line(p1, p2):\n",
    "    A = (p1[1] - p2[1])\n",
    "    B = (p2[0] - p1[0])\n",
    "    C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "    return A, B, -C\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return x,y\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def rotate_image(img, center, angle, width, height):\n",
    "\n",
    "   shape = (img.shape[1], img.shape[0]) # (length, height)\n",
    "\n",
    "   matrix = cv2.getRotationMatrix2D((center[0], center[1]), angle, 1 )\n",
    "   rotated = cv2.warpAffine( img, matrix, shape )\n",
    "\n",
    "   x = int( center[0] - width/2  )\n",
    "   y = int( center[1] - height/2 )\n",
    "\n",
    "   cropped = rotated[ y:y+height, x:x+width ]\n",
    "\n",
    "   return cropped\n",
    "\n",
    "def getTruthValueFromFile(filename):\n",
    "    if filename is None:\n",
    "        return []\n",
    "    truth_values = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line != 'pos' and line != 'neg':\n",
    "                raise Exception('Truth file contains line other than \"pos\" or \"neg\"')\n",
    "            if line == 'pos':                    \n",
    "                truth_values.append(1)\n",
    "            else:\n",
    "                truth_values.append(0)\n",
    "    return truth_values\n",
    "\n",
    "def score_confidence_interval(score_fun, y_true, y_pred, pvalue, niter):\n",
    "    \"\"\"\n",
    "    Calculation of the confidence interval for a given p-value using bootstrap sampling\n",
    "    http://stackoverflow.com/questions/19124239/scikit-learn-roc-curve-with-confidence-intervals\n",
    "    \"\"\"\n",
    "    \n",
    "    n_bootstraps = niter\n",
    "    bootstrapped_scores = []\n",
    "    \n",
    "#     rng_seed = 42  # control reproducibility\n",
    "#     rng = np.random.RandomState(rng_seed)\n",
    "\n",
    "    rng = np.random.RandomState()\n",
    "    for i in range(n_bootstraps):\n",
    "        # bootstrap by sampling with replacement on the prediction indices\n",
    "        indices = rng.randint(0, len(y_pred) - 1, len(y_pred))\n",
    "        \n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            # We need at least one positive and one negative sample for ROC AUC\n",
    "            # to be defined: reject the sample\n",
    "            continue\n",
    "\n",
    "        score = score_fun(y_true[indices], y_pred[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "    \n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "\n",
    "    confidence_lower = sorted_scores[int((1 - pvalue) * len(sorted_scores))] \n",
    "    confidence_upper = sorted_scores[int(pvalue * len(sorted_scores))]\n",
    "\n",
    "    return [confidence_lower, confidence_upper]\n",
    "\n",
    "def auc_confidence_interval(y_true, y_pred, pvalue=0.95, niter=1000):\n",
    "    return score_confidence_interval(roc_auc_score, y_true, y_pred, pvalue, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual detection code, all in a single function:\n",
    "\n",
    "def getmin(data):\n",
    "    half = int(data.shape[0]/2)\n",
    "    top = data.shape[0]\n",
    "    values = np.array([])\n",
    "    for i in range(half, top):\n",
    "        values = np.append(values, np.mean(data[i]))\n",
    "    m = np.min(values)\n",
    "    sd = np.std(values)\n",
    "    return m, sd\n",
    "\n",
    "def predict(data, mint, maxt):\n",
    "    m, sd = getmin(data)\n",
    "    f = (m - mint) / (maxt - mint)\n",
    "    if f < 0: f = 0\n",
    "    if 1 < f: f = 1\n",
    "    score = 1 - f\n",
    "    return score\n",
    "\n",
    "def getPredictions(filename):\n",
    "    # The maximum and minimum allowed ratios of the sides of the green box\n",
    "    maxGreenBoxRatio = 140.0/528\n",
    "    minGreenBoxRatio = 102.0/578\n",
    "\n",
    "    # The maximum allowed ratio of the sides of the final deteted strip\n",
    "    maxStripBoxRatio = 70/480\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the sides of the box defined by the red arrows\n",
    "    maxRedBoxRatio = 42.0/91\n",
    "    minRedBoxRatio = 14.0/104\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the areas of green boxes and red arrow-bounding boxes\n",
    "    maxRedGreenBoxRatio = 3500.0/4000\n",
    "    minRedGreenBoxRatio = 2000.0/4500\n",
    "    # minRedGreenIntersection = 1000.0/4500\n",
    "\n",
    "    # Minimum intensity for binary thresholding of the top portion of the strips\n",
    "    minStripThreshold = 190\n",
    "\n",
    "    # Sensitive area of the strip\n",
    "    stripWidth = 200\n",
    "    stripHeight = 2000\n",
    "    stripHoldY = 900\n",
    "    # maxPeakAlign = 50\n",
    "\n",
    "    # Percentage of the margins to be removed\n",
    "    marginFraction = 0.2\n",
    "\n",
    "    # Red is at the beginning/end of the hue range, so it covers the [0-15] and the [170, 180] \n",
    "    # (hue in OpenCV varies  between 0 and 180 degrees)\n",
    "    lower_red1 = np.array([0, 50, 50]) \n",
    "    upper_red1 = np.array([13, 255, 255])\n",
    "    lower_red2 = np.array([170, 50, 50]) \n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Green is between 20 and 90 (these ranges can be adjusted)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "\n",
    "    # We can also use a large color range to encapsulate both red and green:\n",
    "    lower_redgreen1 = np.array([0, 50, 50]) \n",
    "    upper_redgreen1 = np.array([83, 255, 255])\n",
    "    lower_redgreen2 = np.array([170, 50, 50]) \n",
    "    upper_redgreen2 = np.array([180, 255, 255])    \n",
    "    \n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    \n",
    "    # Processing Step 1: detecting the colored area in the strips\n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    # First, use CLAHE to improve image quality:\n",
    "    # plt.subplot(2, 1, 1)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # image = applyClahetoRGB(image)\n",
    "    # plt.subplot(2, 1, 2)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # First, convert the image to HSV color space, which makes the color detection straightforward\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # These strips have red arrows on a green background, so we define two masks, one for red and the other for green\n",
    "\n",
    "    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1) \n",
    "    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2) \n",
    "\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    red_mask = red_mask1 + red_mask2\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    redgreen_mask1 = cv2.inRange(hsv, lower_redgreen1, upper_redgreen1) \n",
    "    redgreen_mask2 = cv2.inRange(hsv, lower_redgreen2, upper_redgreen2) \n",
    "    mask = redgreen_mask1 + redgreen_mask2\n",
    "      \n",
    "    # Processing Step 2a: determining the bounding boxes for the red arrows.\n",
    "    # Because the red hue seems to be well-conserved between images,\n",
    "    # we have a high confidence of putting a box around all the red arrows. \n",
    "    cnts = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    red_boxes = []\n",
    "    red_rectangles = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( top-left corner(x,y),  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        redBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if redBoxRatio < minRedBoxRatio or maxRedBoxRatio < redBoxRatio: continue\n",
    "        red_boxes += [box[0:]]\n",
    "        red_rectangles += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 3, (255,0,0), -1)    \n",
    "    \n",
    "    # Processing Step 2b: finding green box candidates\n",
    "    # Stage 1:\n",
    "    #     Given a masked version of the image which includes red to green hues,\n",
    "    #     find all green contours\n",
    "    # Stage 2:\n",
    "    #     Declare a green contour to be a green_rect_candidate to be further \n",
    "    #     analyzed if the ratio of the sides of the contour are similar to that\n",
    "    #     observed in the Sherlock strips. \n",
    "    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    green_box_candidates = []\n",
    "    green_rect_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( (x,y) of middle of top side of rect,  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        greenBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if greenBoxRatio < minGreenBoxRatio or maxGreenBoxRatio < greenBoxRatio: continue\n",
    "\n",
    "        area = boxArea(box)\n",
    "        green_box_candidates += [box[0:]]\n",
    "        green_rect_candidates += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 2c: filter the green_box_candidates based on size (imputed from\n",
    "    # the red box areas) and shape (ratio of lengths of the sides).\n",
    "    # Stage 1:\n",
    "    #     Mark all candidate green boxes which are within a particular size range\n",
    "    #     of a red box. Because we can put bounding boxes around red arrows with a \n",
    "    #     high confidence, and there is little-to-no red hue in the source image \n",
    "    #     excluding the red arrows, we can impute that the largest of these marked\n",
    "    #     are the green boxes around the arrows (the contrary would suggest a large\n",
    "    #     green spot in the source image, or some severe hue errors)\n",
    "    # Stage 2:\n",
    "    #     Sort the marked boxes by size; chose the second largest marked box as a\n",
    "    #     representative green box\n",
    "    # Stage 3:\n",
    "    #     Filter out marked green boxes which are not a similar size as the\n",
    "    #     representative green box.\n",
    "\n",
    "    green_boxes = {}\n",
    "    green_rects = {}\n",
    "    for i, red_box in enumerate(red_boxes):\n",
    "        red_box_area = boxArea(red_box)*1.0\n",
    "        for j, green_box in enumerate(green_box_candidates):\n",
    "            green_box_area = boxArea(green_box)*1.0\n",
    "            redGreenBoxRatio = red_box_area/green_box_area\n",
    "            if minRedGreenBoxRatio < redGreenBoxRatio < maxRedGreenBoxRatio:\n",
    "                # now check for intersections:\n",
    "                green_boxes[j] = True\n",
    "                green_rects[j] = True\n",
    "\n",
    "    green_boxes = [green_box_candidates[j] for j in green_boxes]\n",
    "    green_rects = [green_rect_candidates[j] for j in green_rects]\n",
    "    green_boxes.sort(key = lambda box : boxArea(box), reverse=True)\n",
    "    green_rects.sort(key = lambda rect : rectArea(rect), reverse=True)\n",
    "\n",
    "    if len(green_rects) < 2:\n",
    "        raise Exception('Not enough strips')\n",
    "    if rectArea(green_rects[0]) < 1.25* rectArea(green_rects[1]):\n",
    "        greenBoxArea = rectArea(green_rects[1])\n",
    "        green_rect_len = max(green_rects[1][1][0], green_rects[1][1][1])\n",
    "    elif len(green_boxes) < 3 \\\n",
    "            and rectArea(green_rects[1]) < 1.25* rectArea(green_rects[2]):\n",
    "        greenBoxArea = rectArea(green_rects[2])\n",
    "        green_rect_len = max(green_rects[2][1][0], green_rects[2][1][1])\n",
    "    else:\n",
    "        raise Exception('Too much noise in image')\n",
    "\n",
    "    center_boxes = [box for box in green_boxes \n",
    "                     if 0.8*greenBoxArea < boxArea(box) < 1.25*greenBoxArea]\n",
    "    greenBoxArea = statistics.median([boxArea(box) for box in center_boxes])\n",
    "\n",
    "    # Processing Step 3: binary thresholding of the entire image to extract the top part of the strips\n",
    "    ret, thresh = cv2.threshold(image, minStripThreshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Processing Step 4: detect boundary boxes for the top of the strips\n",
    "    grayscale = cv2.cvtColor(thresh, cv2.COLOR_BGR2GRAY)\n",
    "    cnts = cv2.findContours(grayscale, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    # Minimum area of the top strip boxes\n",
    "    minTopBoxArea = 1.8 * greenBoxArea\n",
    "    # Maximum of the top strip boxes\n",
    "    maxTopBoxArea = 5 * greenBoxArea\n",
    "\n",
    "    top_box_candidates = []\n",
    "    top_rects_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        area = boxArea(box)\n",
    "        if area < minTopBoxArea/15 or maxTopBoxArea < area: \n",
    "            continue\n",
    "\n",
    "        top_box_candidates += [box]\n",
    "        top_rects_candidates += [rect]\n",
    "    \n",
    "    # In some cases, the strip signal is so strong that a continuous box gets split up into two boxes. \n",
    "    # We fix this by merging two boxes if the bottom left and top left corners of the respective boxes,\n",
    "    # and the  right and top right corners of the respective boxes are within a threshold distance of\n",
    "    # # each other. \n",
    "    top_boxes = []\n",
    "    top_box_candidates.sort(key = lambda item : item[1][1])\n",
    "    distance_threshold = green_rect_len * 0.15\n",
    "    merged_boxes = {}\n",
    "    tmp = image.copy()\n",
    "    for i in range(0, len(top_box_candidates)):\n",
    "        upper_box = top_box_candidates[i]\n",
    "        if i in merged_boxes:\n",
    "            continue\n",
    "        current_merged_upper_box = upper_box\n",
    "        for j in range(i, len(top_box_candidates)):\n",
    "            lower_box = top_box_candidates[j]\n",
    "            if pointDistance(current_merged_upper_box[3], lower_box[0]) < distance_threshold and \\\n",
    "                    pointDistance(current_merged_upper_box[2], lower_box[1]) < distance_threshold:\n",
    "                # Sometimes the arrows get detected in this step as false boxes -- to filter for this, \n",
    "                # we make sure that boxes can only be concatenated if they have similar width:\n",
    "                if pointDistance(current_merged_upper_box[3], current_merged_upper_box[2]) < \\\n",
    "                        pointDistance(lower_box[0], lower_box[1])*1.5:\n",
    "                    current_merged_upper_box = np.array([current_merged_upper_box[0], \n",
    "                                                         current_merged_upper_box[1], \n",
    "                                                         lower_box[2], lower_box[3]])\n",
    "\n",
    "                    if minTopBoxArea < boxArea(current_merged_upper_box): \n",
    "                        merged_boxes[j] =  True\n",
    "        else:\n",
    "            stripBoxRatio = pointDistance(current_merged_upper_box[0], \n",
    "                                          current_merged_upper_box[1])/ \\\n",
    "                                          pointDistance(current_merged_upper_box[0],\n",
    "                                                        current_merged_upper_box[3])\n",
    "            if minTopBoxArea < boxArea(current_merged_upper_box) and \\\n",
    "                    stripBoxRatio < maxStripBoxRatio: \n",
    "                top_boxes.append(current_merged_upper_box) \n",
    "\n",
    "    for box in top_boxes:\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 5)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 5: construct the boxes that enclose the sensitive strip area\n",
    "    # First, order the top boxes from left to right\n",
    "    top_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "    # Find the red boxes which bound arrows, and then\n",
    "    # order them left to right\n",
    "    red_boxes.sort(key=lambda box: boxArea(box), reverse=True)\n",
    "    red_boxes = red_boxes[0:len(top_boxes)]\n",
    "    red_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "    num_boxes = len(top_boxes)\n",
    "    strip_boxes = []\n",
    "    for i in range(0, num_boxes):\n",
    "        tbox = top_boxes[i]\n",
    "        rbox = red_boxes[i]    \n",
    "\n",
    "        # The corners are expected to be received in the following order:\n",
    "        # 0 = botton left corner\n",
    "        # 1 = top left corner   \n",
    "        # 2 = top right corner \n",
    "        # 3 = bottom right corner\n",
    "\n",
    "        tp0, tp1, tp2, tp3 = tbox[3], tbox[0], tbox[1], tbox[2]\n",
    "        rp0, rp1, rp2, rp3 = rbox[3], rbox[0], rbox[1], rbox[2]\n",
    "\n",
    "        # The intersection of the lines defining the sides of the strip (tp1-tp0 and tp2-tp3)\n",
    "        # with the bottom edge of the red box defines the bottom corners of the area of interest\n",
    "        res1 = intersection(line(tp1, tp0), line(rp0, rp3))\n",
    "        res2 = intersection(line(tp2, tp3), line(rp0, rp3)) \n",
    "\n",
    "        assert(res1 != False and res2 != False), \"Top and center boxes are not intersecting\"\n",
    "\n",
    "        p1 = np.array([int(round(res1[0])), int(round(res1[1]))])\n",
    "        p2 = np.array([int(round(res2[0])), int(round(res2[1]))])\n",
    "\n",
    "        sbox = np.array([p1, tp1, tp2, p2])\n",
    "        strip_boxes += [sbox]\n",
    "    \n",
    "    # Processing Step 6: Extract the strips into separate images\n",
    "    ref_box = np.array([[0, 0],[0, stripHeight],[stripWidth, stripHeight],[stripWidth, 0]], dtype=float)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "#     fig, plots = plt.subplots(1, len(strip_boxes)*3, figsize=(10, 10))\n",
    "    idx = 0\n",
    "    tmp = image.copy()\n",
    "    raw_strip_images = []\n",
    "    for sbx in strip_boxes:\n",
    "        center = (statistics.mean([sbx[0][0], sbx[1][0], sbx[2][0], sbx[3][0]]),\n",
    "                  statistics.mean([sbx[0][1], sbx[1][1], sbx[2][1], sbx[3][1]]))\n",
    "        angle = -1*np.degrees(np.arctan2(sbx[0][0]-sbx[1][0], sbx[0][1] - sbx[1][1]))\n",
    "        #angle = angle if sbx[0][0] < sbx[1][0] else angle*-1\n",
    "        width = int(pointDistance(sbx[1], sbx[2]))\n",
    "        height = int(pointDistance(sbx[0], sbx[1]))\n",
    "#         print(angle)\n",
    "#         print(width)\n",
    "        straigtened_strip = rotate_image(image, center, angle, width, \n",
    "                                                    height)\n",
    "        # Spurious hits often occur at the edges of the strip, so let's\n",
    "        # crop them away\n",
    "        cropped_strip = straigtened_strip[:, \n",
    "                                          int(straigtened_strip.shape[1]*0.1):\n",
    "                                          int(straigtened_strip.shape[1]*0.9)]\n",
    "\n",
    "#         plots[idx].imshow(cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        hsv = cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2HSV)\n",
    "        green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        cnts = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        # Create a copy of the image to draw the bounding boxes on\n",
    "        tmp = cropped_strip.copy()\n",
    "        colored_box_cutoff = tmp.shape[0]\n",
    "        for c in cnts:\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0: continue\n",
    "\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = makeOrderedBox(rect)\n",
    "            if boxArea(box) > 0.10*greenBoxArea:\n",
    "                if box[0][1] < colored_box_cutoff:\n",
    "                    colored_box_cutoff = box[0][1]\n",
    "            tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "            tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 10, (255,0,0), -1)\n",
    "        #plots[idx + 0].imshow(cv2.cvtColor(green_mask, cv2.COLOR_BGR2RGB))\n",
    "#         plots[idx + 0].imshow(cv2.cvtColor(tmp, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        colored_box_cutoff = colored_box_cutoff\n",
    "        final_strip = straigtened_strip[0:colored_box_cutoff, :]\n",
    "#         plots[idx + 1].imshow(cv2.cvtColor(final_strip, cv2.COLOR_BGR2RGB))\n",
    "    #     h, status = cv2.findHomography(final_strip, ref_box)\n",
    "    #     img = cv2.warpPerspective(image, h, (stripWidth, stripHeight))\n",
    "    #     raw_strip_images += [img]\n",
    "        height = final_strip.shape[0]\n",
    "        width = final_strip.shape[1]\n",
    "        h, status = cv2.findHomography(np.array([(0,height), (0,0), (width, 0), (width, height)]), ref_box)\n",
    "        img = cv2.warpPerspective(final_strip, h, (stripWidth, stripHeight))\n",
    "        raw_strip_images += [img]\n",
    "#         plots[idx + 2].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        idx += 3    \n",
    "    \n",
    "    # Processing Step 7: Crop the images to remove the grip of the strips, and the vertical borders\n",
    "    norm_strip_images = []\n",
    "#     fig, plots = plt.subplots(1, len(raw_strip_images), figsize=(10, 10))\n",
    "    idx = 0\n",
    "    for img in raw_strip_images:\n",
    "        # Crop out the top and the bottom parts of the strip, and applying bilateral filtering for smoothing\n",
    "        # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
    "        x0 = int(marginFraction * stripWidth)\n",
    "        x1 = int((1 - marginFraction) * stripWidth)\n",
    "        y0 = 0\n",
    "        y1 = stripHoldY\n",
    "\n",
    "        crop = img[y0:y1, x0:x1]\n",
    "        nimg = cv2.bilateralFilter(crop, 9, 75, 75)\n",
    "        nimg = nimg[30:, :]\n",
    "        norm_strip_images += [nimg]\n",
    "\n",
    "        vimg = cv2.flip(nimg, 0)\n",
    "#         if idx == 1: plots[idx].axis('off')\n",
    "#         plots[idx].imshow(cv2.cvtColor(vimg, cv2.COLOR_BGR2RGB))\n",
    "        idx += 1    \n",
    "    \n",
    "    # Processing Step 7b: Normalize HSV values\n",
    "    correction_method = 'clahe' # {'linear', 'clahe', 'gray', 'he'}\n",
    "    idx = 0\n",
    "    hew_corrected_norm_strip_images = []\n",
    "    for nimg in norm_strip_images:\n",
    "        hsv = cv2.cvtColor(nimg, cv2.COLOR_BGR2HSV)\n",
    "        # determine the hsv color of this strip\n",
    "        if correction_method == 'linear':\n",
    "            # We chose a standard hsv value to normalize all of our images to:\n",
    "            standard_hsv = [16.0/1.5, 17.0/1.5, 243.0/1.5]\n",
    "            # standard_hsv = [16.0, 17.0, 243.0]\n",
    "\n",
    "            rows_hsv = []\n",
    "            for i in range(hsv.shape[0]):\n",
    "                pixels_h = np.zeros(hsv.shape[1])\n",
    "                pixels_s = np.zeros(hsv.shape[1])\n",
    "                pixels_v = np.zeros(hsv.shape[1])\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    pixels_h[j] = hsv[i,j][0]\n",
    "                    pixels_s[j] = hsv[i,j][1]\n",
    "                    pixels_v[j] = hsv[i,j][2]\n",
    "                rows_hsv.append([statistics.median(val) for val in [pixels_h, pixels_s, pixels_v]])\n",
    "                #print(rows_hsv)\n",
    "            rows_hsv = np.array(rows_hsv)\n",
    "            strip_hsv = [statistics.median(rows_hsv[:,0]), \n",
    "                               statistics.median(rows_hsv[:,1]),\n",
    "                               statistics.median(rows_hsv[:,2])]\n",
    "            hue_correction = standard_hsv[0]/strip_hsv[0]\n",
    "            sat_correction = standard_hsv[1]/strip_hsv[1]\n",
    "            val_correction = standard_hsv[2]/strip_hsv[2]\n",
    "            for i in range(hsv.shape[0]):\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    # hsv[i,j][0] = min(179, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][0] = min(180, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][1] = hsv[i,j][1] * sat_correction\n",
    "                    hsv[i,j][2] = hsv[i,j][2] * val_correction\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_BGR2RGB\n",
    "\n",
    "        elif correction_method == 'clahe':\n",
    "            clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(10,10))\n",
    "            hew_corrected_norm_strip_images.append(clahe.apply(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB        \n",
    "\n",
    "        elif correction_method == 'he':\n",
    "            hew_corrected_norm_strip_images.append(\n",
    "                cv2.equalizeHist(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        elif correction_method == 'gray':\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        else:\n",
    "            raise Exception('incorrect normalization type')\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "    # Processing Step 8: make prediction\n",
    "    idx = len(norm_strip_images) - 1\n",
    "    min0 = 0\n",
    "    img0 = hew_corrected_norm_strip_images[idx]\n",
    "    data0 = img0.astype('int32')\n",
    "    min0, _ = getmin(data0)\n",
    "    mint = min0 - LODStandardDeviation\n",
    "    maxt = min0 + LODStandardDeviation\n",
    "\n",
    "def getStripPixelAreaFromFile(filename):\n",
    "    if filename is None:\n",
    "        return None\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            return int(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/VHF/dilution1.jpg\n",
      "[1, 1, 1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 1, 1, 0.5396297234178736]\n",
      "images/VHF/dilution2.jpg\n",
      "[1, 1, 1, 1, 1, 0, 0]\n",
      "[1, 1, 0.6748542304044971, 0.5399643403635797, 0.6111950165359921, 0.7430902242101407]\n",
      "images/VHF/dilution3.jpg\n",
      "[1, 1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0.43364237945283635, 0.5072335600297224]\n",
      "images/VHF/dilution4.jpg\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0.8128037048551615]\n",
      "images/VHF/dilution5.jpg\n",
      "[1, 1, 1, 1, 1, 0, 0]\n",
      "[1, 0.696040164950481, 0.5218723237975731, 0.49699141571895944, 0.5769943106607445, 0.569679017127341]\n",
      "images/VHF/dilution6.jpg\n",
      "[1, 1, 1, 1, 1, 1, 1, 0]\n",
      "[1, 1, 1, 1, 0.654148674778628, 0.5643007421111714, 0.5163601921893545]\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "all_truths = []\n",
    "for test in test_files:\n",
    "    img_fn = 'images/' + test + \".jpg\"\n",
    "    tru_fn = 'images/' + test + \".txt\"\n",
    "\n",
    "    t = getTruthValueFromFile(tru_fn)\n",
    "    s = strip_detection.getPredictions(img_fn, getStripPixelAreaFromFile('images/' + test + '_size.txt') )\n",
    "    all_scores += s\n",
    "    all_truths += t[:-1]\n",
    "    print(img_fn)\n",
    "    print(t)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strips   : 34\n",
      "Number of positives: 29\n",
      "Perc. of positives : 85.29\n",
      "\n",
      "Measures of performance\n",
      "AUC           : 0.77 (0.62, 0.93)\n",
      "Brier         : 0.12\n",
      "Accuracy      : 0.65\n",
      "Sensitivity   : 0.62\n",
      "Specificity   : 0.80\n"
     ]
    }
   ],
   "source": [
    "class_threshold = 0.8\n",
    "p_value = 0.95\n",
    "all_preds = np.array([int(class_threshold < p) for p in all_scores])\n",
    "\n",
    "ytrue = np.array(all_truths)\n",
    "probs = np.array(all_scores)\n",
    "ypred = all_preds\n",
    "\n",
    "auc = roc_auc_score(ytrue, probs)\n",
    "fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "brier = brier_score_loss(ytrue, probs)\n",
    "# cal, dis = caldis(ytrue, probs)\n",
    "acc = accuracy_score(ytrue, ypred)\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(ytrue, ypred)\n",
    "\n",
    "auc_ci = auc_confidence_interval(ytrue, probs, p_value)\n",
    "\n",
    "P = N = 0\n",
    "TP = TN = 0\n",
    "FP = FN = 0\n",
    "for i in range(len(ytrue)):\n",
    "    if ytrue[i] == 1:\n",
    "        P += 1\n",
    "        if ypred[i] == 1: TP += 1\n",
    "        else: FN += 1\n",
    "    else:\n",
    "        N += 1\n",
    "        if ypred[i] == 0: TN += 1\n",
    "        else: FP += 1\n",
    "            \n",
    "sens = float(TP)/P\n",
    "spec = float(TN)/N\n",
    "\n",
    "# Positive and Negative Predictive Values\n",
    "# https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values\n",
    "ppv = float(TP) / (TP + FP)\n",
    "npv = float(TN) / (TN + FN)\n",
    "        \n",
    "# Likelihood ratios\n",
    "# https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing\n",
    "lr_pos = sens / (1 - spec) if spec < 1 else np.inf\n",
    "lr_neg = (1 - sens) / spec if 0 < spec else np.inf\n",
    "\n",
    "# print \"True outcomes:\", ytrue\n",
    "# print \"Prediction   :\", ypred\n",
    "cfr = 100 * (float(np.sum(ytrue)) / len(ytrue))\n",
    "print(\"Number of strips   :\", len(ytrue))\n",
    "print(\"Number of positives:\", np.sum(ytrue)) \n",
    "print(\"Perc. of positives : %0.2f\" % cfr)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Measures of performance\") \n",
    "print(\"AUC           : %0.2f (%0.2f, %0.2f)\" % (auc, auc_ci[0], auc_ci[1])) \n",
    "print(\"Brier         : %0.2f\" % brier) \n",
    "# print(\"Calibration   :\", cal) \n",
    "# print(\"Discrimination:\", dis) \n",
    "print(\"Accuracy      : %0.2f\" % acc) \n",
    "print(\"Sensitivity   : %0.2f\" % sens) \n",
    "print(\"Specificity   : %0.2f\" % spec) \n",
    "# print(\"PPV           : %0.2f\" % ppv) \n",
    "# print(\"NPV           : %0.2f\" % npv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3TV9Znv8fdDLoAEAkIgEeQeRRGIEBCUq4BcgqhztFbGeh9Ea2c8s86adnXW6Zw1c3pWZ3Vmjp3TWspYtbZjwdow3UAAKYKigICK3C8BBAK2IiiFcMvlOX/sDY0xkE3IL7+9sz+vtbLYv9vezxfC/uzf7dnm7oiISOpqEXYBIiISLgWBiEiKUxCIiKQ4BYGISIpTEIiIpLj0sAu4XJ06dfKePXuGXYaISFJ5//33P3P3nLqWJV0Q9OzZkw0bNoRdhohIUjGz/RdbpkNDIiIpTkEgIpLiFAQiIilOQSAikuIUBCIiKU5BICKS4hQEIiIpTkEgIpLiFAQiIilOQSAikuIUBCIiKU5BICKS4hQEIiIpLrAgMLMXzexTM9tykeVmZv9uZqVmtsnMBgdVi4iIXFyQewQvA5MvsXwKkB/7mQn8NMBaRETkIgILAnd/Gzh2iVXuAl7xqLVAezPLC6oeEZFE8eyzz/Lss8+GXcYFYX4xTVfgYI3psti8T2qvaGYzie410L179yYpTkSksbk7e/bsYePGjWGX8iVhBoHVMc/rWtHd5wBzAAoLC+tcR0QkkX3xxRcsWLCAvXv3cvr0aVq3bh12SReEGQRlwLU1prsBh0OqRUQkENXV1axfv57ly5djZkydOpUVK1aEXdaXhBkEEeAZM5sL3AIcd/evHBYSEUlmr7/+Otu3b6dv375MmzaN7OzssEv6isCCwMx+DYwFOplZGfAPQAaAu88GSoCpQClwCng0qFpERJpSVVUVAGlpaRQUFNCvXz8GDBiAWV1HxMMXWBC4+wP1LHfgm0G9vohIGA4fPkwkEqF///6MGjWK6667LuyS6hXmoSERkWajoqKClStXsmbNGtq0aUPnzp3DLiluCgIRkStUVlbG/PnzOXbsGDfffDN33HEHrVq1CrusuCkIRESu0Plj/9/4xjfo3bt3yNVcPgWBiEgD7N69m7KyMsaNG0fXrl355je/SYsWydnHU0EgInIZTp06xdKlS9m0aRM5OTmMHDmSjIyMpA0BUBCIiMTF3dm2bRslJSWcOXOG0aNHM2rUKNLTk/9tNPlHICLNzpw5c3j11VfDLuNLqqqqOHToEBkZGXTs2JHly5c3+Lk2btxIQUFBI1Z3ZZJ3X0ZEmq1XX301YRqznT59GojeHJabm0teXh6ZmZlX9JwFBQXMmDGjMcprFNojEJGEVFBQwMqVK0N7/c8//5wFCxawb98+ZsyYQX5+fmi1BE1BICJSQ3V1Ne+99x5vvvkmLVq0oKioiL59+4ZdVqAUBCIiNfzmN79hx44d5OfnM23aNNq1axd2SYFTEIhIyqvZJG7w4MHceOON3HTTTQnbJK6xKQhEJKUdOnToQpO40aNHN+tzARejIBCRlFRRUcGKFStYu3YtWVlZ5Obmhl1SaBQEIpJyDh48yPz58/n8888ZMmQIEyZMSKomcY1NQSAiKadFixa0aNGChx56iF69eoVdTugUBCKSEnbt2sWhQ4cuNIl7+umnk7o/UGNSEIhIs1ZeXs7SpUvZvHkznTt3bhZN4hqbgkAkSSViP57G0hi9eNydrVu3snjxYs6cOcPYsWMZOXIkaWlpjVRl86EgEElS5/vxJFLzssbSGL14ysvLiUQidO7cmenTpyfVV0c2NQWBSBILux9PonF3du3axXXXXUdWVhaPPfYYnTt31mGgeuhvR0SahWPHjvHKK68wd+5cSktLAcjNzVUIxEF7BCKS1Kqrq1m7di0rVqwgLS2NO++8s9k3iWtsCgIRSWrnm8Rdf/31FBUV0bZt27BLSjoKAhFJOpWVlZjZhSZx/fv3p3///inTJK6xKQhEJKmUlZURiUS46aabUrZJXGNTEIhIUjh37tyFJnHt2rUjLy8v7JKaDQWBiCS8mk3iCgsLmTBhAi1btgy7rGYj0OuqzGyyme00s1Iz+04dy7PNbIGZfWRmW83s0SDrEZHklJaWRlpaGg8//DBFRUUKgUYWWBCYWRrwE2AKcCPwgJndWGu1bwLb3H0QMBb4VzPLDKomEUkeO3fuZPny5QBcc801PPXUU/Ts2TPcopqpIPcIhgGl7r7X3c8Bc4G7aq3jQFuLnurPAo4BlQHWJCIJrry8nNdff525c+eye/duKioqAHRjWICCPEfQFThYY7oMuKXWOj8GIsBhoC1wv7tX134iM5sJzATo3r17IMVK89Ocm7JB4zRmSyTuzubNm1myZAnnzp1j3Lhx3HbbbWoS1wSCjNi6Luj1WtOTgI3ANUAB8GMza/eVjdznuHuhuxfm5OQ0fqXSLJ1vytZcNUZjtkRSXl7OokWL6NixI08++SSjR49WCDSRIPcIyoBra0x3I/rJv6ZHgR+4uwOlZrYP6AesC7AuSSFqypbY3J2dO3dy/fXXX2gSl5OTo8NATSzIv+31QL6Z9YqdAP460cNANR0AxgOYWRfgemBvgDWJSII4evQov/jFL5g3b96FJnFdunRRCIQgsD0Cd680s2eApUAa8KK7bzWzWbHls4F/Al42s81EDyV9290/C6omEQlfdXU1a9asYeXKlaSnpzN9+nQ1iQtZoDeUuXsJUFJr3uwajw8DdwRZg4gkltdee42dO3fSr18/pk6dqiZxCUB3FotI4Go2iSssLGTgwIHccMMNahKXIBQEIhKogwcPXmgSN2bMGB0GSkAKAhEJxLlz51i+fDnr1q0jOzubrl27hl2SXISCQEQa3YEDByguLub48eMMHTqU8ePHqz9QAlMQiEijS09PJzMzk0cffVTdAJKAgkBEGsX27ds5fPgw48ePv9AkTieDk4OCQESuyMmTJ1m8eDHbtm0jNzeX0aNHk5GRoRBIIgoCEWkQd2fTpk0sWbKEiooKbr/9dm699Vb1B0pCCgIRaZDy8nJKSkro0qUL06dPp1OnTmGXJA2kIBCRuLk7O3bsoF+/fheaxHXu3FmHgZKcujuJSFw+++wzXnrpJV577bUvNYlTCCQ/7RGIyCVVVVWxevVq3nrrLTIyMrj77rt1d3AzoyAQkUt67bXX2LVrFzfeeCNTpkwhKysr7JKkkSkIROQrajaJGzZsGAUFBdxwww1hlyUBURCIyJccOHCASCTCgAEDGDNmDH369Am7JAmYgkBEADh79izLly9n/fr1tG/fnm7duoVdkjQRBYGIsH//fubPn8/x48cZNmwY48ePJzMzM+yypIkoCESEzMxMWrZsyWOPPca1114bdjnSxBQEIinI3dm+fTuHDh1i4sSJ5OXlMWvWLN0TkKIUBCIp5sSJE5SUlLBjxw7y8vKoqKhQk7gUpyAQSRHuzsaNG3njjTeorKxkwoQJjBgxghYt1GAg1SkIRFJEeXk5S5YsIS8vjzvvvJOOHTuGXZIkCAWBSDNWXV3Njh07uOGGG8jKyuLxxx8nJydHh4HkS7RPKNJMHTlyhJdeeonf/OY3F5rEqVOo1EV7BCLNTFVVFe+++y5vv/02mZmZ3HPPPWoSJ5cUVxCY2W+BF4HF7l4dbEmJY86cObz66qthlyENtHHjRgoKCsIuo8nNmzeP3bt3079/f6ZMmUKbNm3CLkkSXLyHhn4KzAB2m9kPzKxfgDUljFdffZWNGzeGXYY0UEFBATNmzAi7jCZRUVFBVVUVALfccgv3338/9957r0JA4hLXHoG7/x74vZllAw8Ay8zsIPAfwK/cvaKu7cxsMvAjIA14wd1/UMc6Y4HngAzgM3cf05CBBKWgoICVK1eGXYbIRX388ccsWLCAAQMGMHbsWDWJk8sW9zkCM+sIPAh8A/gQ+E9gJPAwMLaO9dOAnwATgTJgvZlF3H1bjXXaA88Dk939gJl1bvhQRFLL2bNnWbZsGe+//z4dOnSgR48eYZckSSrecwTFQD/gl8Cd7v5JbNE8M9twkc2GAaXuvjf2HHOBu4BtNdaZARS7+wEAd//08ocgknr2799PcXExJ06cYPjw4YwbN05N4qTB4t0jeMHdS2rOMLOW7n7W3Qsvsk1X4GCN6TLgllrrXAdkmNlKoC3wI3d/pfYTmdlMYCZA9+7d4yxZpPnKzMykdevW3HfffWoXLVcs3pPF/7uOeWvq2aaui5W91nQ6MAQoAiYB/9PMrvvKRu5z3L3Q3QtzcnLiqVekWXF3tmzZwrJlywDIy8vjySefVAhIo7jkHoGZ5RL9ZN/azG7mz2/u7YCr6nnuMqBmP9tuwOE61vnM3cuBcjN7GxgE7IqvfJHm78SJEyxatIidO3dyzTXXqEmcNLr6Dg1NAh4h+ib+bzXmnwC+W8+264F8M+sFHAK+TvScQE2/A35sZulAJtFDR/83rspFmjl358MPP+SNN96gqqqKiRMnMnz4cDWJk0Z3ySBw918AvzCz/+buv72cJ3b3SjN7BlhK9PLRF919q5nNii2f7e7bzWwJsAmoJnouYkuDRiLSzJSXl7N06VLy8vKYPn06V199ddglSTNV36GhB939V0BPM/vb2svd/d/q2Kzm8hKgpNa82bWmfwj8MO6KRZqx6upqtm3bRv/+/cnKyuKJJ56gU6dOOgwkgarv0ND52xKzgi5EJNV9+umnRCIRDh06RMuWLcnPz0cXR0hTqO/Q0M9iD5939yNNUI9IyqmqqmLVqlWsWrWKVq1a8Rd/8RdqEidNKt77CFab2T5gHtEbwD4PsCaRlHK+SdyAAQOYNGmS+gNJk4u311C+mQ0jeuXP35vZNmBu7PyBiFymiooKzIz09HSGDx9OYWEh1133lVtoRJpE3Nehufs6d/9boq0jjgG/CKwqkWbs448/5qc//SmrVq0CoHfv3goBCVW8vYbaAfcQ3SPoA8wnGggiEqczZ86wbNkyPvjgAzp06ECvXr3CLkkEiP8cwUfAfwH/6O71tZYQkVo+/vhjiouLOXnyJCNGjGDcuHFkZGSEXZYIEH8Q9Hb32n2CRCROrVq1ok2bNtx///107do17HJEvqS+G8qec/dngYiZfSUI3H16YJWJJLHzTeIOHz7MpEmTyM3NZebMmboxTBJSfXsEv4z9+S9BFyLSXBw/fpxFixaxe/duunXrpiZxkvDqu6Hs/djDAnf/Uc1lZvY3wFtBFSaSbNyd999/n2XLluHuTJo0iWHDhqlJnCS8eH9DH65j3iONWIdI0isvL2fZsmV07dqVp556Sp1CJWnUd47gAaKto3uZWaTGorbA0SALE0kG1dXVbN26lZtuuomsrCz+6q/+io4dO+owkCSV+s4RrAY+AToB/1pj/gmiraNFUtYf//hHIpEIhw8fpnXr1vTt25dOnTqFXZbIZavvHMF+YD8womnKEUl8lZWVrFq1infeeYdWrVpx77330qdPn7DLEmmw+g4NvePuI83sBF/+vmED3N3bBVqdSAKaN28epaWlDBw4kEmTJnHVVfV9a6tIYqtvj2Bk7M+2TVOOSGI6d+4cLVq0ID09nREjRjBs2DDy8/PDLkukUcR1SYOZ9TGzlrHHY83sr82sfbCliSSGvXv3fqVJnEJAmpN4r237LVBlZn2BnwO9gFcDq0okAZw5c4ZIJMIvf/lLWrRoQe/evcMuSSQQ8fYaqo59Gf09wHPu/v/M7MMgCxMJ0759+yguLqa8vJzbbruNMWPGqEmcNFvxBkFF7J6Ch4E7Y/P0v0KardatW9OuXTseeOABrrnmmrDLEQlUvIeGHiV6Cen33X2fmfUC9O1k0my4Ox999BFLly4FIDc3lyeeeEIhICkh3q+q3Ab8dY3pfcAPgipKpCkdP36chQsXUlpayrXXXqsmcZJy4v2GstuA/wX0iG1z/j4CnT2TpOXubNiwgd///ve4O5MnT2bo0KHqDyQpJ95zBD8H/jvwPlAVXDkiTae8vJzly5fTrVs37rzzTtq31xXRkpriDYLj7r440EpEmkB1dTVbtmxhwIABF5rEXX311ToMJCkt3iBYYWY/BIqBs+dnuvsHgVQlEoA//OEPRCIRPvnkE6666ir69u1Lx44dwy5LJHTxBsEtsT8La8xz4PZLbWRmk4EfAWnAC+5e5wlmMxsKrAXud/fX46xJJC6VlZW89dZbvPvuu1x11VXcd9999O3bN+yyRBJGvFcNjbvcJzazNOAnwESgDFhvZpHYFUi11/tnYOnlvoZIPObOncuePXsYNGgQkyZNonXr1mGXJJJQ4r1qqAvwf4Br3H2Kmd0IjHD3n19is2FAqbvvjT3HXOAuYFut9b5FtIXF0MstXuRiajaJu+222xg+fLj2AkQuIt7r5F4m+on9/N01u4Bn69mmK3CwxnRZbN4FZtYVuAeYfaknMrOZZrbBzDYcOXIkzpIlVe3Zs4fnn3+et99+G4BevXopBEQuId4g6OTurwHVAO5eSf2XkdZ1GYbXmn4O+La7X/K53H2Ouxe6e2FOTk6cJUuqOX36NL/73e/41a9+RXp6ut78ReIU78nicjPrSOyN3MyGA8fr2aYMuLbGdDfgcK11CoG5sUv3OgFTzazS3f8rzrpEgGir6Pnz51NeXs7IkSMZM2YM6enx/nqLpLZ4/6f8LRAB+pjZu0AOcG8926wH8mN9iQ4BXwdm1FzB3Xudf2xmLwMLFQLSEFdddRXZ2dnMmDGDvLy8sMsRSSqXPDRkZkPNLDd2v8AY4LtE7yN4g+gn/ouKHT56hui5he3Aa+6+1cxmmdmsRqleUpa7s3HjRhYvjt7nmJuby+OPP64QEGmA+vYIfgZMiD2+Ffh7olf5FABzqGevwN1LgJJa8+o8Mezuj9Rfrgh88cUXLFy4kD179tC9e3c1iRO5QvUFQZq7H4s9vh+Y4+6/BX5rZhuDLU3ky9yddevWsXz5csyMKVOmMHToUAWAyBWqNwjMLD12mGc8MPMythVpVOXl5axYsYIePXpQVFSkJnEijaS+N/NfA2+Z2WfAaWAVQOy7i+u7akjkilVVVbFlyxYGDhxIVlYWM2fOpEOHDtoLEGlElwwCd/++mS0H8oA33P38fQAtiJ4rEAnMJ598QiQS4Q9/+ANZWVn06dOHq6++OuyyRJqdeg/vuPvaOubtCqYcEaioqOCtt95i9erVtGnThq997Wv06dMn7LJEmi0d55eEM2/ePPbs2UNBQQF33HGHmsSJBExBIAnh7NmzpKWlkZ6ezsiRIxkxYoT2AkSaiIJAQrd7924WLlzIoEGDuP322+nZs2fYJYmkFAWBhObUqVMsXbqUTZs20alTJ/Lz88MuSSQlKQgkFHv37qW4uJjTp08zevRoRo0apSZxIiHR/zwJRZs2bejQoQMPPvggubm5YZcjktLi/T4CkSvi7nz44YeUlERbT3Xp0oXHHntMISCSALRHIIH7/PPPWbhwIXv37qVHjx5qEieSYBQEEpjq6mrWrVvHm2++iZlRVFTEkCFDFAAiCUZBIIE5deoUK1eupEePHkybNo3s7OywSxKROigIpFFVVVWxefNmBg0aRFZWFk8++STt27fXXoBIAlMQSKM5fPgwkUiEP/7xj7Rt25Y+ffrQoUOHsMsSkXooCOSKVVRUsHLlStasWUNWVhb333+/2kOIJBEFgVyxuXPnsnfvXgYPHszEiRNp1apV2CWJyGVQEEiD1GwSN2rUKEaOHEmvXr3CLktEGkBBIJdt165dLFq0iIEDBzJ+/Hg1iRNJcgoCidupU6dYsmQJmzdvJicnh+uvvz7skkSkESgIJC579uyhuLiYM2fOMGbMGEaNGkVaWlrYZYlII1AQSFyysrLo2LEjRUVFdOnSJexyRKQRqemc1Mnd+eCDD77UJO7RRx9VCIg0Q9ojkK84duwYCxYs4OOPP6Znz55UVlaSnp6uu4NFmikFgVxQXV3N2rVrWbFiBWlpaUybNo3BgwcrAESauUAPDZnZZDPbaWalZvadOpb/pZltiv2sNrNBQdYjl3bq1CnefvttevfuzdNPP61OoSIpIrA9AjNLA34CTATKgPVmFnH3bTVW2weMcffPzWwKMAe4Jaia5Kuqqqr46KOPuPnmm8nKymLWrFlkZ2crAERSSJCHhoYBpe6+F8DM5gJ3AReCwN1X11h/LdAtwHqklkOHDhGJRPj000/Jzs6mT58+tG/fPuyyRKSJBRkEXYGDNabLuPSn/ceBxXUtMLOZwEyA7t27N1Z9KauiooIVK1awdu1asrKyeOCBB9QkTiSFBRkEdR1b8DpXNBtHNAhG1rXc3ecQPWxEYWFhnc8h8TvfJG7IkCFMmDBBTeJEUlyQQVAGXFtjuhtwuPZKZjYQeAGY4u5HA6wnpZ05c4b09HTS09MZPXo0o0aNUo8gEQGCDYL1QL6Z9QIOAV8HZtRcwcy6A8XAN9x9V4C1pLSdO3eyaNEiBg0axPjx4+nRo0fYJYlIAgksCNy90syeAZYCacCL7r7VzGbFls8Gvgd0BJ6PXaVS6e6FQdWUasrLy1myZAlbtmyhc+fO3HDDDWGXJCIJKNAbyty9BCipNW92jcdPAE8EWUOqKi0tpbi4mLNnzzJ27FhGjhypJnEiUifdWdxMtWvXjs6dO1NUVEROTk7Y5YhIAlPTuWbC3dmwYQMLFy4EoHPnzjzyyCMKARGpl/YImoGjR4+yYMEC9u/fT69evS40iRMRiYfeLZJYdXU1a9asYeXKlaSlpTF9+nQKCgrUHkJELouCIImdOnWKd955hz59+lBUVETbtm3DLklEkpCCIMlUVlby0UcfMXjwYLKysnjyySfVJE5EroiCIImUlZURiUQ4cuQI7du3V5M4EWkUCoIkcO7cOd58803ee+892rVrx4wZM9QkTkQajYIgCcydO5d9+/ZRWFjIhAkTaNmyZdgliUgzoiBIUGfOnCEtLY2MjAzGjBnDmDFj1CNIRAKhIEhAO3bsuNAkbsKECQoAEQmUgiCBnDx5ksWLF7Nt2zZyc3Pp379/2CWJSApQECSI3bt3M3/+fM6dO8ftt9/OrbfeqiZxItIkFAQJIjs7my5dulBUVESnTp3CLkdEUoiazoXE3Vm/fj0LFiwAok3iHn74YYWAiDQ57RGE4LPPPmPBggUcOHCA3r17q0mciIRK7z5NqLq6mtWrV7Ny5UoyMjK46667GDRokNpDiEioFARN6NSpU7z77rvk5+czdepUNYkTkYSgIAhYZWUlGzduZMiQIWRlZTFr1iyys7PDLktE5AIFQYAOHDhAJBLh6NGjXH311fTu3VshICIJR0EQgHPnzrF8+XLWrVtHdnY2Dz74IL179w67LBGROikIAnC+SdywYcMYP348mZmZYZckInJRCoJGcvr0adLT08nIyGDs2LGMHTuW7t27h12WiEi9FASNYNu2bZSUlDBo0CAmTpyoABCRpKIguAInT56kpKSE7du3k5uby0033RR2SSIil01B0EC7d++muLiYiooKxo8fz4gRI9QkTkSSkoKggdq3b09eXh5Tp05VfyARSWpqOhcnd+e9994jEokAkJOTw0MPPaQQEJGkF2gQmNlkM9tpZqVm9p06lpuZ/Xts+SYzGxxkPQ115MgRXnrpJZYsWcKJEyeorKwMuyQRkUYT2KEhM0sDfgJMBMqA9WYWcfdtNVabAuTHfm4Bfhr7MyG4O3/605/42c9+RmZmJnfffTcDBw5UkzgRaVaCPEcwDCh1970AZjYXuAuoGQR3Aa+4uwNrzay9meW5+ycB1hW36upqjh8/Tr9+/Zg8eTJZWVlhlyQi0uiCDIKuwMEa02V89dN+Xet0Bb4UBGY2E5gJNOk1+kOGDGHAgAHce++9TfaaIiJNLcggqOv4iTdgHdx9DjAHoLCw8CvLg/Lcc8811UuJiIQmyJPFZcC1Naa7AYcbsI6IiAQoyCBYD+SbWS8zywS+DkRqrRMBHopdPTQcOJ4o5wdERFJFYIeG3L3SzJ4BlgJpwIvuvtXMZsWWzwZKgKlAKXAKeDSoekREpG6B3lns7iVE3+xrzptd47ED3wyyBhERuTTdWSwikuIUBCIiKU5BICKS4hQEIiIpTkEgIpLiFAQiIilOQSAikuIUBCIiKU5BICKS4hQEIiIpTkEgIpLiFAQiIinOon3fkoeZHQH2N+FLdgI+a8LXa2oaX3JrzuNrzmODph9fD3fPqWtB0gVBUzOzDe5eGHYdQdH4kltzHl9zHhsk1vh0aEhEJMUpCEREUpyCoH5zwi4gYBpfcmvO42vOY4MEGp/OEYiIpDjtEYiIpDgFgYhIilMQxJjZZDPbaWalZvadOpabmf17bPkmMxscRp0NFcf4/jI2rk1mttrMBoVRZ0PUN7Ya6w01syozu7cp67tS8YzPzMaa2UYz22pmbzV1jVcijt/NbDNbYGYfxcb3aBh1NoSZvWhmn5rZlossT4z3FXdP+R8gDdgD9AYygY+AG2utMxVYDBgwHHgv7LobeXy3Ah1ij6cky/jiGVuN9d4ESoB7w667kf/t2gPbgO6x6c5h193I4/su8M+xxznAMSAz7NrjHN9oYDCw5SLLE+J9RXsEUcOAUnff6+7ngLnAXbXWuQt4xaPWAu3NLK+pC22gesfn7qvd/fPY5FqgWxPX2FDx/NsBfAv4LfBpUxbXCOIZ3wyg2N0PALh7Mo0xnvE50NbMDMgiGgSVTVtmw7j720TrvZiEeF9REER1BQ7WmC6LzbvcdRLV5db+ONFPKcmg3rGZWVfgHmB2E9bVWOL5t7sO6GBmK83sfTN7qMmqu3LxjO/HwA3AYWAz8DfuXt005QUuId5X0pv6BROU1TGv9nW18ayTqOKu3czGEQ2CkYFW1HjiGdtzwLfdvSr6oTKpxDO+dGAIMB5oDawxs7Xuvivo4hpBPOObBGwEbgf6AMvMbJW7/yno4ppAQryvKAiiyoBra0x3I/rp43LXSVRx1W5mA4EXgCnufrSJartS8YytEJgbC4FOwFQzq3T3/2qaEq9IvL+bn7l7OVBuZm8Dg4BkCIJ4xvco8AOPHlQvNY7vVaYAAAP7SURBVLN9QD9gXdOUGKiEeF/RoaGo9UC+mfUys0zg60Ck1joR4KHYWf7hwHF3/6SpC22gesdnZt2BYuAbSfJJ8rx6x+buvdy9p7v3BF4Hnk6SEID4fjd/B4wys3Qzuwq4BdjexHU2VDzjO0B0bwcz6wJcD+xt0iqDkxDvK9ojANy90syeAZYSvYrhRXffamazYstnE73aZCpQCpwi+iklKcQ5vu8BHYHnY5+cKz1BOiNeSpxjS1rxjM/dt5vZEmATUA284O51Xq6YaOL89/sn4GUz20z0UMq33T0p2lOb2a+BsUAnMysD/gHIgMR6X1GLCRGRFKdDQyIiKU5BICKS4hQEIiIpTkEgIpLiFAQiIilOQSDNRn2dHuPYfpqZfRjrcrnNzJ5s5Pr+0cwmxB6PinXS3GhmXc3s9Xq2fcHMbow9/m5j1iWiy0el2TCz0cBJok28brrMbTOA/cAwdy8zs5ZAT3ffGUCpmNlsop0mX2rAtifdPSuAsiRFaY9Amo04Oj1eSluiN1gejT3X2fMhYGYvm9lsM1tlZrvMbFpsfpqZ/dDM1sd6yV/YgzCzvzOzzbG9ix/UeJ57zewJ4GvA98zsP82s5/m9mNhz/kts201m9q3Y/JVmVhh7rtaxPYn/NLN/MrO/qfG63zezv27g34GkKN1ZLAK4+zEziwD7zWw5sBD4dY0ulz2BMUSbnq0ws77AQ0RbAgyN7UG8a2ZvEO2Dczdwi7ufMrOra73WC2Y2Eljo7q+bWc8ai2cCvYCbY3fd1t72O2b2jLsXAMS2LQZ+ZGYtiLZoGNY4fyuSKhQEIjHu/oSZDQAmAP8DmAg8Elv8WiwUdpvZXqJv9ncAA+3P33iWDeTHtn/J3U/Fnvdy9lImALPdvTKebd39YzM7amY3A12AD5OoYaAkCAWBpAwzSwPej01G3P17tddx983AZjP7JbCPPwdB7ZNpTrTvzbfcfWmt15lcx/pxl9mAbV8gWmcu8GIDX1dSmM4RSMpw9yp3L4j9fCkEzCzLzMbWmFVA9OTxefeZWQsz60P0axV3Em2U9lTsRDNmdp2ZtQHeAB6LdQKl9uGderwBzDKz9EtsW3H+NWPmA5OBobGaRC6L9gik2air06O7/zzezYG/M7OfAaeBcv68NwDRN/63iB5+meXuZ8zsBaLnDj6waMvWI8Dd7r7EzAqADWZ2jmiHyXgv+XyB6DeObTKzCuA/iH5DV01zYss/cPe/dPdzZrYC+MLdq+J8HZELdPmoSD3M7GViJ3bDrqUusZPEHwD3ufvusOuR5KNDQyJJLHaTWSmwXCEgDaU9AhGRFKc9AhGRFKcgEBFJcQoCEZEUpyAQEUlxCgIRkRT3/wHNMHb2rPjo3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.plot([0, 1], [0, 1], 'k--', c='grey')\n",
    "plt.plot(fpr, tpr, color='black')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "fig.savefig('reader-roc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
