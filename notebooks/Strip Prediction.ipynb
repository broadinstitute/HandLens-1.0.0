{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import cv2\n",
    "import imutils\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [\n",
    "               'VHF/dilution1',\n",
    "               'VHF/dilution2',    \n",
    "               'VHF/dilution3',\n",
    "               'VHF/dilution4',\n",
    "               'VHF/dilution5',\n",
    "               'VHF/dilution6',\n",
    "             ]\n",
    "\n",
    "# test_files = ['tickborne/Ana_DNA_LF',\n",
    "#               'tickborne/Ana_FTA_LF',\n",
    "#               'tickborne/Bab_DNA_LF',\n",
    "#               'tickborne/Bab_FTA_LF']\n",
    "\n",
    "# test_files = ['SL-IV-1',\n",
    "#               'EBOV-1-G2']\n",
    "\n",
    "# #               'EBOV-2-G9', # too dark\n",
    "# #              'SL-LOD-1.jpg', # too dark\n",
    "              \n",
    "#               'LF-1-patients',\n",
    "#               'N2-LOD-1',\n",
    "#               'N2-LOD-2',\n",
    "#               'N2-LOD-3',\n",
    "#               'NG-LOD-1']\n",
    "\n",
    "LODStandardDeviation = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utilities\n",
    "\n",
    "def makeOrderedBox(rect):\n",
    "    \"\"\"\n",
    "    Return a 4-element tuple representing the corners of a box:\n",
    "        idx 0 = top left corner   \n",
    "        idx 1 = top right corner \n",
    "        idx 2 = bottom right corner\n",
    "        idx 3 = botton left corner\n",
    "    \"\"\"\n",
    "    box0 = cv2.boxPoints(rect)\n",
    "    box0 = np.int0(box0)\n",
    "    \n",
    "    xval = [pt[0] for pt in box0]\n",
    "    yval = [pt[1] for pt in box0]\n",
    "    \n",
    "    x0 = np.mean(xval)\n",
    "    y0 = np.mean(yval)\n",
    "  \n",
    "    angles = []\n",
    "    for i in range(0, len(box0)):\n",
    "        xi = box0[i][0]\n",
    "        yi = box0[i][1]        \n",
    "        x = xi - x0\n",
    "        y = yi - y0\n",
    "        a = np.arctan2(y, x)\n",
    "        val = [a, i]\n",
    "        angles += [val]\n",
    "\n",
    "    angles.sort(key=lambda val: val[0], reverse=False)    \n",
    "    box = np.array([box0[val[1]] for val in angles])\n",
    "    \n",
    "    return box\n",
    "\n",
    "def boxMinX(box):\n",
    "    return min([pt[0] for pt in box])\n",
    "\n",
    "def boxMaxX(box):  \n",
    "    return max([pt[0] for pt in box])\n",
    "\n",
    "def boxMinY(box):\n",
    "    return min([pt[1] for pt in box])\n",
    "\n",
    "def boxMaxY(box):\n",
    "    return max([pt[1] for pt in box])\n",
    "\n",
    "def boxArea(box):\n",
    "    x0 = np.mean([pt[0] for pt in box])\n",
    "    y0 = np.mean([pt[1] for pt in box])\n",
    "    p0 = np.array([x0, y0])\n",
    "    \n",
    "    area = 0\n",
    "    n = len(box)\n",
    "    for i in range(0, n):\n",
    "        p1 = box[i]\n",
    "        if i < n - 1:\n",
    "            p2 = box[i + 1]\n",
    "        else:\n",
    "            p2 = box[0]\n",
    "            \n",
    "        # Heron's Formula\n",
    "        a = np.linalg.norm(p1-p0)\n",
    "        b = np.linalg.norm(p2-p0)\n",
    "        c = np.linalg.norm(p1-p2)\n",
    "        s = (a + b + c) / 2\n",
    "        triarea = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "        \n",
    "        area += triarea        \n",
    "        \n",
    "    return area\n",
    "\n",
    "def rectArea(rect):\n",
    "    return rect[1][0]*rect[1][1]\n",
    "\n",
    "def pointDistance(p1, p2):\n",
    "    \"\"\"\n",
    "    Given two poiints, each represented by a tuple (x1, y1), calculate the eucalidian distance\n",
    "    between them.\n",
    "    \"\"\"\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5\n",
    "\n",
    "def boxesIntersection(box1, box2, img_shape):\n",
    "    # Calculate the total intersection area of two boxes:\n",
    "    \n",
    "    # first sort the points in the boxes as (x,y) in descending order:\n",
    "    box1.sort()\n",
    "    box2.sort()\n",
    "    \n",
    "    blanked_image = np.zeros( shape = (img_shape[0], img_shape[1], 1), dtype = \"uint8\")\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    \n",
    "    return cv2.countNonZero(blanked_image)\n",
    "\n",
    "def applyClahetoRGB(bgr_imb):\n",
    "    \n",
    "    lab= cv2.cvtColor(bgr_imb, cv2.COLOR_BGR2LAB)\n",
    "    # Split lab image to different channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    \n",
    "    #Convert image from LAB Color model to RGB model\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return final\n",
    "\n",
    "def intersectLines(pt1, pt2, ptA, ptB): \n",
    "    \"\"\" this returns the intersection of Line(pt1,pt2) and Line(ptA,ptB)\n",
    "        https://www.cs.hmc.edu/ACM/lectures/intersections.html    \n",
    "        \n",
    "        returns a tuple: (xi, yi, valid, r, s), where\n",
    "        (xi, yi) is the intersection\n",
    "        r is the scalar multiple such that (xi,yi) = pt1 + r*(pt2-pt1)\n",
    "        s is the scalar multiple such that (xi,yi) = pt1 + s*(ptB-ptA)\n",
    "            valid == 0 if there are 0 or inf. intersections (invalid)\n",
    "            valid == 1 if it has a unique intersection ON the segment    \"\"\"\n",
    "\n",
    "    DET_TOLERANCE = 0.00000001\n",
    "\n",
    "    # the first line is pt1 + r*(pt2-pt1)\n",
    "    # in component form:\n",
    "    x1, y1 = pt1;   x2, y2 = pt2\n",
    "    dx1 = x2 - x1;  dy1 = y2 - y1\n",
    "\n",
    "    # the second line is ptA + s*(ptB-ptA)\n",
    "    x, y = ptA;   xB, yB = ptB;\n",
    "    dx = xB - x;  dy = yB - y;\n",
    "\n",
    "    # we need to find the (typically unique) values of r and s\n",
    "    # that will satisfy\n",
    "    #\n",
    "    # (x1, y1) + r(dx1, dy1) = (x, y) + s(dx, dy)\n",
    "    #\n",
    "    # which is the same as\n",
    "    #\n",
    "    #    [ dx1  -dx ][ r ] = [ x-x1 ]\n",
    "    #    [ dy1  -dy ][ s ] = [ y-y1 ]\n",
    "    #\n",
    "    # whose solution is\n",
    "    #\n",
    "    #    [ r ] = _1_  [  -dy   dx ] [ x-x1 ]\n",
    "    #    [ s ] = DET  [ -dy1  dx1 ] [ y-y1 ]\n",
    "    #\n",
    "    # where DET = (-dx1 * dy + dy1 * dx)\n",
    "    #\n",
    "    # if DET is too small, they're parallel\n",
    "    #\n",
    "    DET = (-dx1 * dy + dy1 * dx)\n",
    "\n",
    "    if math.fabs(DET) < DET_TOLERANCE: return (0,0,0,0,0)\n",
    "\n",
    "    # now, the determinant should be OK\n",
    "    DETinv = 1.0/DET\n",
    "\n",
    "    # find the scalar amount along the \"self\" segment\n",
    "    r = DETinv * (-dy  * (x-x1) +  dx * (y-y1))\n",
    "\n",
    "    # find the scalar amount along the input line\n",
    "    s = DETinv * (-dy1 * (x-x1) + dx1 * (y-y1))\n",
    "\n",
    "    # return the average of the two descriptions\n",
    "    xi = (x1 + r*dx1 + x + s*dx)/2.0\n",
    "    yi = (y1 + r*dy1 + y + s*dy)/2.0\n",
    "    return ( xi, yi, 1, r, s )\n",
    "\n",
    "def line(p1, p2):\n",
    "    A = (p1[1] - p2[1])\n",
    "    B = (p2[0] - p1[0])\n",
    "    C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "    return A, B, -C\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return x,y\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def rotate_image(img, center, angle, width, height):\n",
    "\n",
    "   shape = (img.shape[1], img.shape[0]) # (length, height)\n",
    "\n",
    "   matrix = cv2.getRotationMatrix2D((center[0], center[1]), angle, 1 )\n",
    "   rotated = cv2.warpAffine( img, matrix, shape )\n",
    "\n",
    "   x = int( center[0] - width/2  )\n",
    "   y = int( center[1] - height/2 )\n",
    "\n",
    "   cropped = rotated[ y:y+height, x:x+width ]\n",
    "\n",
    "   return cropped\n",
    "\n",
    "def getTruthValueFromFile(filename):\n",
    "    if filename is None:\n",
    "        return []\n",
    "    truth_values = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line != 'pos' and line != 'neg':\n",
    "                raise Exception('Truth file contains line other than \"pos\" or \"neg\"')\n",
    "            if line == 'pos':                    \n",
    "                truth_values.append(1)\n",
    "            else:\n",
    "                truth_values.append(0)\n",
    "    return truth_values\n",
    "\n",
    "def score_confidence_interval(score_fun, y_true, y_pred, pvalue, niter):\n",
    "    \"\"\"\n",
    "    Calculation of the confidence interval for a given p-value using bootstrap sampling\n",
    "    http://stackoverflow.com/questions/19124239/scikit-learn-roc-curve-with-confidence-intervals\n",
    "    \"\"\"\n",
    "    \n",
    "    n_bootstraps = niter\n",
    "    bootstrapped_scores = []\n",
    "    \n",
    "#     rng_seed = 42  # control reproducibility\n",
    "#     rng = np.random.RandomState(rng_seed)\n",
    "\n",
    "    rng = np.random.RandomState()\n",
    "    for i in range(n_bootstraps):\n",
    "        # bootstrap by sampling with replacement on the prediction indices\n",
    "        indices = rng.randint(0, len(y_pred) - 1, len(y_pred))\n",
    "        \n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            # We need at least one positive and one negative sample for ROC AUC\n",
    "            # to be defined: reject the sample\n",
    "            continue\n",
    "\n",
    "        score = score_fun(y_true[indices], y_pred[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "    \n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "\n",
    "    confidence_lower = sorted_scores[int((1 - pvalue) * len(sorted_scores))] \n",
    "    confidence_upper = sorted_scores[int(pvalue * len(sorted_scores))]\n",
    "\n",
    "    return [confidence_lower, confidence_upper]\n",
    "\n",
    "def auc_confidence_interval(y_true, y_pred, pvalue=0.95, niter=1000):\n",
    "    return score_confidence_interval(roc_auc_score, y_true, y_pred, pvalue, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual detection code, all in a single function:\n",
    "\n",
    "def getmin(data):\n",
    "    half = int(data.shape[0]/2)\n",
    "    top = data.shape[0]\n",
    "    values = np.array([])\n",
    "    for i in range(half, top):\n",
    "        values = np.append(values, np.mean(data[i]))\n",
    "    m = np.min(values)\n",
    "    sd = np.std(values)\n",
    "    return m, sd\n",
    "\n",
    "def predict(data, mint, maxt):\n",
    "    m, sd = getmin(data)\n",
    "    f = (m - mint) / (maxt - mint)\n",
    "    if f < 0: f = 0\n",
    "    if 1 < f: f = 1\n",
    "    score = 1 - f\n",
    "    return score\n",
    "\n",
    "def getPredictions(filename):\n",
    "    # The maximum and minimum allowed ratios of the sides of the green box\n",
    "    maxGreenBoxRatio = 140.0/528\n",
    "    minGreenBoxRatio = 102.0/578\n",
    "\n",
    "    # The maximum allowed ratio of the sides of the final deteted strip\n",
    "    maxStripBoxRatio = 70/480\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the sides of the box defined by the red arrows\n",
    "    maxRedBoxRatio = 42.0/91\n",
    "    minRedBoxRatio = 14.0/104\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the areas of green boxes and red arrow-bounding boxes\n",
    "    maxRedGreenBoxRatio = 3500.0/4000\n",
    "    minRedGreenBoxRatio = 2000.0/4500\n",
    "    # minRedGreenIntersection = 1000.0/4500\n",
    "\n",
    "    # Minimum intensity for binary thresholding of the top portion of the strips\n",
    "    minStripThreshold = 190\n",
    "\n",
    "    # Sensitive area of the strip\n",
    "    stripWidth = 200\n",
    "    stripHeight = 2000\n",
    "    stripHoldY = 900\n",
    "    # maxPeakAlign = 50\n",
    "\n",
    "    # Percentage of the margins to be removed\n",
    "    marginFraction = 0.2\n",
    "\n",
    "    # Red is at the beginning/end of the hue range, so it covers the [0-15] and the [170, 180] \n",
    "    # (hue in OpenCV varies  between 0 and 180 degrees)\n",
    "    lower_red1 = np.array([0, 50, 50]) \n",
    "    upper_red1 = np.array([13, 255, 255])\n",
    "    lower_red2 = np.array([170, 50, 50]) \n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Green is between 20 and 90 (these ranges can be adjusted)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "\n",
    "    # We can also use a large color range to encapsulate both red and green:\n",
    "    lower_redgreen1 = np.array([0, 50, 50]) \n",
    "    upper_redgreen1 = np.array([83, 255, 255])\n",
    "    lower_redgreen2 = np.array([170, 50, 50]) \n",
    "    upper_redgreen2 = np.array([180, 255, 255])    \n",
    "    \n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    \n",
    "    # Processing Step 1: detecting the colored area in the strips\n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    # First, use CLAHE to improve image quality:\n",
    "    # plt.subplot(2, 1, 1)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # image = applyClahetoRGB(image)\n",
    "    # plt.subplot(2, 1, 2)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # First, convert the image to HSV color space, which makes the color detection straightforward\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # These strips have red arrows on a green background, so we define two masks, one for red and the other for green\n",
    "\n",
    "    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1) \n",
    "    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2) \n",
    "\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    red_mask = red_mask1 + red_mask2\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    redgreen_mask1 = cv2.inRange(hsv, lower_redgreen1, upper_redgreen1) \n",
    "    redgreen_mask2 = cv2.inRange(hsv, lower_redgreen2, upper_redgreen2) \n",
    "    mask = redgreen_mask1 + redgreen_mask2\n",
    "      \n",
    "    # Processing Step 2a: determining the bounding boxes for the red arrows.\n",
    "    # Because the red hue seems to be well-conserved between images,\n",
    "    # we have a high confidence of putting a box around all the red arrows. \n",
    "    cnts = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    red_boxes = []\n",
    "    red_rectangles = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( top-left corner(x,y),  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        redBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if redBoxRatio < minRedBoxRatio or maxRedBoxRatio < redBoxRatio: continue\n",
    "        red_boxes += [box[0:]]\n",
    "        red_rectangles += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 3, (255,0,0), -1)    \n",
    "    \n",
    "    # Processing Step 2b: finding green box candidates\n",
    "    # Stage 1:\n",
    "    #     Given a masked version of the image which includes red to green hues,\n",
    "    #     find all green contours\n",
    "    # Stage 2:\n",
    "    #     Declare a green contour to be a green_rect_candidate to be further \n",
    "    #     analyzed if the ratio of the sides of the contour are similar to that\n",
    "    #     observed in the Sherlock strips. \n",
    "    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    green_box_candidates = []\n",
    "    green_rect_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( (x,y) of middle of top side of rect,  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        greenBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if greenBoxRatio < minGreenBoxRatio or maxGreenBoxRatio < greenBoxRatio: continue\n",
    "\n",
    "        area = boxArea(box)\n",
    "        green_box_candidates += [box[0:]]\n",
    "        green_rect_candidates += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 2c: filter the green_box_candidates based on size (imputed from\n",
    "    # the red box areas) and shape (ratio of lengths of the sides).\n",
    "    # Stage 1:\n",
    "    #     Mark all candidate green boxes which are within a particular size range\n",
    "    #     of a red box. Because we can put bounding boxes around red arrows with a \n",
    "    #     high confidence, and there is little-to-no red hue in the source image \n",
    "    #     excluding the red arrows, we can impute that the largest of these marked\n",
    "    #     are the green boxes around the arrows (the contrary would suggest a large\n",
    "    #     green spot in the source image, or some severe hue errors)\n",
    "    # Stage 2:\n",
    "    #     Sort the marked boxes by size; chose the second largest marked box as a\n",
    "    #     representative green box\n",
    "    # Stage 3:\n",
    "    #     Filter out marked green boxes which are not a similar size as the\n",
    "    #     representative green box.\n",
    "\n",
    "    green_boxes = {}\n",
    "    green_rects = {}\n",
    "    for i, red_box in enumerate(red_boxes):\n",
    "        red_box_area = boxArea(red_box)*1.0\n",
    "        for j, green_box in enumerate(green_box_candidates):\n",
    "            green_box_area = boxArea(green_box)*1.0\n",
    "            redGreenBoxRatio = red_box_area/green_box_area\n",
    "            if minRedGreenBoxRatio < redGreenBoxRatio < maxRedGreenBoxRatio:\n",
    "                # now check for intersections:\n",
    "                green_boxes[j] = True\n",
    "                green_rects[j] = True\n",
    "\n",
    "    green_boxes = [green_box_candidates[j] for j in green_boxes]\n",
    "    green_rects = [green_rect_candidates[j] for j in green_rects]\n",
    "    green_boxes.sort(key = lambda box : boxArea(box), reverse=True)\n",
    "    green_rects.sort(key = lambda rect : rectArea(rect), reverse=True)\n",
    "\n",
    "    if len(green_rects) < 2:\n",
    "        raise Exception('Not enough strips')\n",
    "    if rectArea(green_rects[0]) < 1.25* rectArea(green_rects[1]):\n",
    "        greenBoxArea = rectArea(green_rects[1])\n",
    "        green_rect_len = max(green_rects[1][1][0], green_rects[1][1][1])\n",
    "    elif len(green_boxes) < 3 \\\n",
    "            and rectArea(green_rects[1]) < 1.25* rectArea(green_rects[2]):\n",
    "        greenBoxArea = rectArea(green_rects[2])\n",
    "        green_rect_len = max(green_rects[2][1][0], green_rects[2][1][1])\n",
    "    else:\n",
    "        raise Exception('Too much noise in image')\n",
    "\n",
    "    center_boxes = [box for box in green_boxes \n",
    "                     if 0.8*greenBoxArea < boxArea(box) < 1.25*greenBoxArea]\n",
    "    greenBoxArea = statistics.median([boxArea(box) for box in center_boxes])\n",
    "\n",
    "    # Processing Step 3: binary thresholding of the entire image to extract the top part of the strips\n",
    "    ret, thresh = cv2.threshold(image, minStripThreshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Processing Step 4: detect boundary boxes for the top of the strips\n",
    "    grayscale = cv2.cvtColor(thresh, cv2.COLOR_BGR2GRAY)\n",
    "    cnts = cv2.findContours(grayscale, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    # Minimum area of the top strip boxes\n",
    "    minTopBoxArea = 1.8 * greenBoxArea\n",
    "    # Maximum of the top strip boxes\n",
    "    maxTopBoxArea = 5 * greenBoxArea\n",
    "\n",
    "    top_box_candidates = []\n",
    "    top_rects_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        area = boxArea(box)\n",
    "#         if area < minTopBoxArea/15 or maxTopBoxArea < area: \n",
    "        if area < minTopBoxArea/15: \n",
    "            continue\n",
    "\n",
    "        top_box_candidates += [box]\n",
    "        top_rects_candidates += [rect]\n",
    "    \n",
    "    # In some cases, the strip signal is so strong that a continuous box gets split up into two boxes. \n",
    "    # We fix this by merging two boxes if the bottom left and top left corners of the respective boxes,\n",
    "    # and the  right and top right corners of the respective boxes are within a threshold distance of\n",
    "    # # each other. \n",
    "    top_boxes = []\n",
    "    top_box_candidates.sort(key = lambda item : item[1][1])\n",
    "    distance_threshold = green_rect_len * 0.15\n",
    "    merged_boxes = {}\n",
    "    tmp = image.copy()\n",
    "    for i in range(0, len(top_box_candidates)):\n",
    "        upper_box = top_box_candidates[i]\n",
    "        if i in merged_boxes:\n",
    "            continue\n",
    "        current_merged_upper_box = upper_box\n",
    "        for j in range(i, len(top_box_candidates)):\n",
    "            lower_box = top_box_candidates[j]\n",
    "            if pointDistance(current_merged_upper_box[3], lower_box[0]) < distance_threshold and \\\n",
    "                    pointDistance(current_merged_upper_box[2], lower_box[1]) < distance_threshold:\n",
    "                # Sometimes the arrows get detected in this step as false boxes -- to filter for this, \n",
    "                # we make sure that boxes can only be concatenated if they have similar width:\n",
    "                if pointDistance(current_merged_upper_box[3], current_merged_upper_box[2]) < \\\n",
    "                        pointDistance(lower_box[0], lower_box[1])*1.5:\n",
    "                    current_merged_upper_box = np.array([current_merged_upper_box[0], \n",
    "                                                         current_merged_upper_box[1], \n",
    "                                                         lower_box[2], lower_box[3]])\n",
    "\n",
    "                    if minTopBoxArea < boxArea(current_merged_upper_box): \n",
    "                        merged_boxes[j] =  True\n",
    "        else:\n",
    "            stripBoxRatio = pointDistance(current_merged_upper_box[0], \n",
    "                                          current_merged_upper_box[1])/ \\\n",
    "                                          pointDistance(current_merged_upper_box[0],\n",
    "                                                        current_merged_upper_box[3])\n",
    "            if minTopBoxArea < boxArea(current_merged_upper_box) and \\\n",
    "                    stripBoxRatio < maxStripBoxRatio: \n",
    "                top_boxes.append(current_merged_upper_box) \n",
    "\n",
    "    for box in top_boxes:\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 5)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 5: construct the boxes that enclose the sensitive strip area\n",
    "    # First, order the top boxes from left to right\n",
    "    top_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "    # Find the red boxes which bound arrows, and then\n",
    "    # order them left to right\n",
    "    red_boxes.sort(key=lambda box: boxArea(box), reverse=True)\n",
    "    red_boxes = red_boxes[0:len(top_boxes)]\n",
    "    red_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "    num_boxes = len(top_boxes)\n",
    "    strip_boxes = []\n",
    "    for i in range(0, num_boxes):\n",
    "        tbox = top_boxes[i]\n",
    "        rbox = red_boxes[i]    \n",
    "\n",
    "        # The corners are expected to be received in the following order:\n",
    "        # 0 = botton left corner\n",
    "        # 1 = top left corner   \n",
    "        # 2 = top right corner \n",
    "        # 3 = bottom right corner\n",
    "\n",
    "        tp0, tp1, tp2, tp3 = tbox[3], tbox[0], tbox[1], tbox[2]\n",
    "        rp0, rp1, rp2, rp3 = rbox[3], rbox[0], rbox[1], rbox[2]\n",
    "\n",
    "        # The intersection of the lines defining the sides of the strip (tp1-tp0 and tp2-tp3)\n",
    "        # with the bottom edge of the red box defines the bottom corners of the area of interest\n",
    "        res1 = intersection(line(tp1, tp0), line(rp0, rp3))\n",
    "        res2 = intersection(line(tp2, tp3), line(rp0, rp3)) \n",
    "\n",
    "        assert(res1 != False and res2 != False), \"Top and center boxes are not intersecting\"\n",
    "\n",
    "        p1 = np.array([int(round(res1[0])), int(round(res1[1]))])\n",
    "        p2 = np.array([int(round(res2[0])), int(round(res2[1]))])\n",
    "\n",
    "        sbox = np.array([p1, tp1, tp2, p2])\n",
    "        strip_boxes += [sbox]\n",
    "    \n",
    "    # Processing Step 6: Extract the strips into separate images\n",
    "    ref_box = np.array([[0, 0],[0, stripHeight],[stripWidth, stripHeight],[stripWidth, 0]], dtype=float)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "#     fig, plots = plt.subplots(1, len(strip_boxes)*3, figsize=(10, 10))\n",
    "    idx = 0\n",
    "    tmp = image.copy()\n",
    "    raw_strip_images = []\n",
    "    for sbx in strip_boxes:\n",
    "        center = (statistics.mean([sbx[0][0], sbx[1][0], sbx[2][0], sbx[3][0]]),\n",
    "                  statistics.mean([sbx[0][1], sbx[1][1], sbx[2][1], sbx[3][1]]))\n",
    "        angle = -1*np.degrees(np.arctan2(sbx[0][0]-sbx[1][0], sbx[0][1] - sbx[1][1]))\n",
    "        #angle = angle if sbx[0][0] < sbx[1][0] else angle*-1\n",
    "        width = int(pointDistance(sbx[1], sbx[2]))\n",
    "        height = int(pointDistance(sbx[0], sbx[1]))\n",
    "#         print(angle)\n",
    "#         print(width)\n",
    "        straigtened_strip = rotate_image(image, center, angle, width, \n",
    "                                                    height)\n",
    "        # Spurious hits often occur at the edges of the strip, so let's\n",
    "        # crop them away\n",
    "        cropped_strip = straigtened_strip[:, \n",
    "                                          int(straigtened_strip.shape[1]*0.1):\n",
    "                                          int(straigtened_strip.shape[1]*0.9)]\n",
    "\n",
    "#         plots[idx].imshow(cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        hsv = cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2HSV)\n",
    "        green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        cnts = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        # Create a copy of the image to draw the bounding boxes on\n",
    "        tmp = cropped_strip.copy()\n",
    "        colored_box_cutoff = tmp.shape[0]\n",
    "        for c in cnts:\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0: continue\n",
    "\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = makeOrderedBox(rect)\n",
    "            if boxArea(box) > 0.10*greenBoxArea:\n",
    "                if box[0][1] < colored_box_cutoff:\n",
    "                    colored_box_cutoff = box[0][1]\n",
    "            tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "            tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 10, (255,0,0), -1)\n",
    "        #plots[idx + 0].imshow(cv2.cvtColor(green_mask, cv2.COLOR_BGR2RGB))\n",
    "#         plots[idx + 0].imshow(cv2.cvtColor(tmp, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        colored_box_cutoff = colored_box_cutoff\n",
    "        final_strip = straigtened_strip[0:colored_box_cutoff, :]\n",
    "#         plots[idx + 1].imshow(cv2.cvtColor(final_strip, cv2.COLOR_BGR2RGB))\n",
    "    #     h, status = cv2.findHomography(final_strip, ref_box)\n",
    "    #     img = cv2.warpPerspective(image, h, (stripWidth, stripHeight))\n",
    "    #     raw_strip_images += [img]\n",
    "        height = final_strip.shape[0]\n",
    "        width = final_strip.shape[1]\n",
    "        h, status = cv2.findHomography(np.array([(0,height), (0,0), (width, 0), (width, height)]), ref_box)\n",
    "        img = cv2.warpPerspective(final_strip, h, (stripWidth, stripHeight))\n",
    "        raw_strip_images += [img]\n",
    "#         plots[idx + 2].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        idx += 3    \n",
    "    \n",
    "    # Processing Step 7: Crop the images to remove the grip of the strips, and the vertical borders\n",
    "    norm_strip_images = []\n",
    "#     fig, plots = plt.subplots(1, len(raw_strip_images), figsize=(10, 10))\n",
    "    idx = 0\n",
    "    for img in raw_strip_images:\n",
    "        # Crop out the top and the bottom parts of the strip, and applying bilateral filtering for smoothing\n",
    "        # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
    "        x0 = int(marginFraction * stripWidth)\n",
    "        x1 = int((1 - marginFraction) * stripWidth)\n",
    "        y0 = 0\n",
    "        y1 = stripHoldY\n",
    "\n",
    "        crop = img[y0:y1, x0:x1]\n",
    "        nimg = cv2.bilateralFilter(crop, 9, 75, 75)\n",
    "        nimg = nimg[30:, :]\n",
    "        norm_strip_images += [nimg]\n",
    "\n",
    "        vimg = cv2.flip(nimg, 0)\n",
    "#         if idx == 1: plots[idx].axis('off')\n",
    "#         plots[idx].imshow(cv2.cvtColor(vimg, cv2.COLOR_BGR2RGB))\n",
    "        idx += 1    \n",
    "    \n",
    "    # Processing Step 7b: Normalize HSV values\n",
    "    correction_method = 'clahe' # {'linear', 'clahe', 'gray', 'he'}\n",
    "    idx = 0\n",
    "    hew_corrected_norm_strip_images = []\n",
    "    for nimg in norm_strip_images:\n",
    "        hsv = cv2.cvtColor(nimg, cv2.COLOR_BGR2HSV)\n",
    "        # determine the hsv color of this strip\n",
    "        if correction_method == 'linear':\n",
    "            # We chose a standard hsv value to normalize all of our images to:\n",
    "            standard_hsv = [16.0/1.5, 17.0/1.5, 243.0/1.5]\n",
    "            # standard_hsv = [16.0, 17.0, 243.0]\n",
    "\n",
    "            rows_hsv = []\n",
    "            for i in range(hsv.shape[0]):\n",
    "                pixels_h = np.zeros(hsv.shape[1])\n",
    "                pixels_s = np.zeros(hsv.shape[1])\n",
    "                pixels_v = np.zeros(hsv.shape[1])\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    pixels_h[j] = hsv[i,j][0]\n",
    "                    pixels_s[j] = hsv[i,j][1]\n",
    "                    pixels_v[j] = hsv[i,j][2]\n",
    "                rows_hsv.append([statistics.median(val) for val in [pixels_h, pixels_s, pixels_v]])\n",
    "                #print(rows_hsv)\n",
    "            rows_hsv = np.array(rows_hsv)\n",
    "            strip_hsv = [statistics.median(rows_hsv[:,0]), \n",
    "                               statistics.median(rows_hsv[:,1]),\n",
    "                               statistics.median(rows_hsv[:,2])]\n",
    "            hue_correction = standard_hsv[0]/strip_hsv[0]\n",
    "            sat_correction = standard_hsv[1]/strip_hsv[1]\n",
    "            val_correction = standard_hsv[2]/strip_hsv[2]\n",
    "            for i in range(hsv.shape[0]):\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    # hsv[i,j][0] = min(179, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][0] = min(180, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][1] = hsv[i,j][1] * sat_correction\n",
    "                    hsv[i,j][2] = hsv[i,j][2] * val_correction\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_BGR2RGB\n",
    "\n",
    "        elif correction_method == 'clahe':\n",
    "            clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(10,10))\n",
    "            hew_corrected_norm_strip_images.append(clahe.apply(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB        \n",
    "\n",
    "        elif correction_method == 'he':\n",
    "            hew_corrected_norm_strip_images.append(\n",
    "                cv2.equalizeHist(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        elif correction_method == 'gray':\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        else:\n",
    "            raise Exception('incorrect normalization type')\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "    # Processing Step 8: make prediction\n",
    "    idx = len(norm_strip_images) - 1\n",
    "    min0 = 0\n",
    "    img0 = hew_corrected_norm_strip_images[idx]\n",
    "    data0 = img0.astype('int32')\n",
    "    min0, _ = getmin(data0)\n",
    "    mint = min0 - LODStandardDeviation\n",
    "    maxt = min0 + LODStandardDeviation\n",
    "\n",
    "    preds = []\n",
    "    for img in hew_corrected_norm_strip_images:\n",
    "        data = img.astype('int32') \n",
    "        nrows = data.shape[0]\n",
    "        if not idx == 0:\n",
    "            pred = predict(data, mint, maxt)\n",
    "#             print(pred)\n",
    "            preds += [pred]\n",
    "        idx -= 1\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/VHF/dilution1.jpg\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 0.6428763440860212]\n",
      "images/VHF/dilution2.jpg\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "[1, 1, 0.7982526881720431, 0.700940860215054, 0.6204301075268818, 0.6788978494623656]\n",
      "images/VHF/dilution3.jpg\n",
      "[1, 1, 1, 1, 0]\n",
      "[1, 1, 1, 0.5126344086021505, 0.5103494623655915]\n",
      "images/VHF/dilution4.jpg\n",
      "[1, 1, 1, 0]\n",
      "[1, 1, 1, 0.6764784946236558]\n",
      "images/VHF/dilution5.jpg\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "[1, 0.7716397849462366, 0.7129032258064514, 0.6306451612903226, 0.5797043010752687, 0.5454301075268817]\n",
      "images/VHF/dilution6.jpg\n",
      "[1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 0.7908602150537634, 0.5470430107526885, 0.5709677419354839]\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "all_truths = []\n",
    "for test in test_files:\n",
    "    img_fn = 'images/' + test + \".jpg\"\n",
    "    tru_fn = 'images/' + test + \".txt\"\n",
    "\n",
    "    t = getTruthValueFromFile(tru_fn)\n",
    "    s = getPredictions(img_fn)\n",
    "    all_scores += s\n",
    "    all_truths += t[:-1]\n",
    "    print(img_fn)\n",
    "    print(t[:-1])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strips   : 34\n",
      "Number of positives: 29\n",
      "Perc. of positives : 85.29\n",
      "\n",
      "Measures of performance\n",
      "AUC           : 0.87 (0.77, 0.97)\n",
      "Brier         : 0.10\n",
      "Accuracy      : 0.82\n",
      "Sensitivity   : 0.79\n",
      "Specificity   : 1.00\n"
     ]
    }
   ],
   "source": [
    "class_threshold = 0.7\n",
    "p_value = 0.95\n",
    "all_preds = np.array([int(class_threshold < p) for p in all_scores])\n",
    "\n",
    "ytrue = np.array(all_truths)\n",
    "probs = np.array(all_scores)\n",
    "ypred = all_preds\n",
    "\n",
    "auc = roc_auc_score(ytrue, probs)\n",
    "fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "brier = brier_score_loss(ytrue, probs)\n",
    "# cal, dis = caldis(ytrue, probs)\n",
    "acc = accuracy_score(ytrue, ypred)\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(ytrue, ypred)\n",
    "\n",
    "auc_ci = auc_confidence_interval(ytrue, probs, p_value)\n",
    "\n",
    "P = N = 0\n",
    "TP = TN = 0\n",
    "FP = FN = 0\n",
    "for i in range(len(ytrue)):\n",
    "    if ytrue[i] == 1:\n",
    "        P += 1\n",
    "        if ypred[i] == 1: TP += 1\n",
    "        else: FN += 1\n",
    "    else:\n",
    "        N += 1\n",
    "        if ypred[i] == 0: TN += 1\n",
    "        else: FP += 1\n",
    "            \n",
    "sens = float(TP)/P\n",
    "spec = float(TN)/N\n",
    "\n",
    "# Positive and Negative Predictive Values\n",
    "# https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values\n",
    "ppv = float(TP) / (TP + FP)\n",
    "npv = float(TN) / (TN + FN)\n",
    "        \n",
    "# Likelihood ratios\n",
    "# https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing\n",
    "lr_pos = sens / (1 - spec) if spec < 1 else np.inf\n",
    "lr_neg = (1 - sens) / spec if 0 < spec else np.inf\n",
    "\n",
    "# print \"True outcomes:\", ytrue\n",
    "# print \"Prediction   :\", ypred\n",
    "cfr = 100 * (float(np.sum(ytrue)) / len(ytrue))\n",
    "print(\"Number of strips   :\", len(ytrue))\n",
    "print(\"Number of positives:\", np.sum(ytrue)) \n",
    "print(\"Perc. of positives : %0.2f\" % cfr)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Measures of performance\") \n",
    "print(\"AUC           : %0.2f (%0.2f, %0.2f)\" % (auc, auc_ci[0], auc_ci[1])) \n",
    "print(\"Brier         : %0.2f\" % brier) \n",
    "# print(\"Calibration   :\", cal) \n",
    "# print(\"Discrimination:\", dis) \n",
    "print(\"Accuracy      : %0.2f\" % acc) \n",
    "print(\"Sensitivity   : %0.2f\" % sens) \n",
    "print(\"Specificity   : %0.2f\" % spec) \n",
    "# print(\"PPV           : %0.2f\" % ppv) \n",
    "# print(\"NPV           : %0.2f\" % npv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.plot([0, 1], [0, 1], 'k--', c='grey')\n",
    "plt.plot(fpr, tpr, color='black')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "fig.savefig('reader-roc.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
