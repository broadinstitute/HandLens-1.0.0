{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import cv2\n",
    "import imutils\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = ['SL-IV-1']\n",
    "              \n",
    "# test_files = ['EBOV-1-G2',\n",
    "# #               'EBOV-2-G9', # too dark\n",
    "# #              'SL-LOD-1.jpg', # too dark\n",
    "#               'LF-1-patients',\n",
    "#               'N2-LOD-1',\n",
    "#               'N2-LOD-2',\n",
    "#               'N2-LOD-3',\n",
    "#               'NG-LOD-1']\n",
    "\n",
    "LODStandardDeviation = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utilities\n",
    "\n",
    "def makeOrderedBox(rect):\n",
    "    \"\"\"\n",
    "    Return a 4-element tuple representing the corners of a box:\n",
    "        idx 0 = top left corner   \n",
    "        idx 1 = top right corner \n",
    "        idx 2 = bottom right corner\n",
    "        idx 3 = botton left corner\n",
    "    \"\"\"\n",
    "    box0 = cv2.boxPoints(rect)\n",
    "    box0 = np.int0(box0)\n",
    "    \n",
    "    xval = [pt[0] for pt in box0]\n",
    "    yval = [pt[1] for pt in box0]\n",
    "    \n",
    "    x0 = np.mean(xval)\n",
    "    y0 = np.mean(yval)\n",
    "  \n",
    "    angles = []\n",
    "    for i in range(0, len(box0)):\n",
    "        xi = box0[i][0]\n",
    "        yi = box0[i][1]        \n",
    "        x = xi - x0\n",
    "        y = yi - y0\n",
    "        a = np.arctan2(y, x)\n",
    "        val = [a, i]\n",
    "        angles += [val]\n",
    "\n",
    "    angles.sort(key=lambda val: val[0], reverse=False)    \n",
    "    box = np.array([box0[val[1]] for val in angles])\n",
    "    \n",
    "    return box\n",
    "\n",
    "def boxMinX(box):\n",
    "    return min([pt[0] for pt in box])\n",
    "\n",
    "def boxMaxX(box):  \n",
    "    return max([pt[0] for pt in box])\n",
    "\n",
    "def boxMinY(box):\n",
    "    return min([pt[1] for pt in box])\n",
    "\n",
    "def boxMaxY(box):\n",
    "    return max([pt[1] for pt in box])\n",
    "\n",
    "def boxArea(box):\n",
    "    x0 = np.mean([pt[0] for pt in box])\n",
    "    y0 = np.mean([pt[1] for pt in box])\n",
    "    p0 = np.array([x0, y0])\n",
    "    \n",
    "    area = 0\n",
    "    n = len(box)\n",
    "    for i in range(0, n):\n",
    "        p1 = box[i]\n",
    "        if i < n - 1:\n",
    "            p2 = box[i + 1]\n",
    "        else:\n",
    "            p2 = box[0]\n",
    "            \n",
    "        # Heron's Formula\n",
    "        a = np.linalg.norm(p1-p0)\n",
    "        b = np.linalg.norm(p2-p0)\n",
    "        c = np.linalg.norm(p1-p2)\n",
    "        s = (a + b + c) / 2\n",
    "        triarea = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "        \n",
    "        area += triarea        \n",
    "        \n",
    "    return area\n",
    "\n",
    "def rectArea(rect):\n",
    "    return rect[1][0]*rect[1][1]\n",
    "\n",
    "def pointDistance(p1, p2):\n",
    "    \"\"\"\n",
    "    Given two poiints, each represented by a tuple (x1, y1), calculate the eucalidian distance\n",
    "    between them.\n",
    "    \"\"\"\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5\n",
    "\n",
    "def boxesIntersection(box1, box2, img_shape):\n",
    "    # Calculate the total intersection area of two boxes:\n",
    "    \n",
    "    # first sort the points in the boxes as (x,y) in descending order:\n",
    "    box1.sort()\n",
    "    box2.sort()\n",
    "    \n",
    "    blanked_image = np.zeros( shape = (img_shape[0], img_shape[1], 1), dtype = \"uint8\")\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    cv2.drawContours(blanked_image, [box], 0, (255, 255, 255), thickness = -1)\n",
    "    \n",
    "    return cv2.countNonZero(blanked_image)\n",
    "\n",
    "def applyClahetoRGB(bgr_imb):\n",
    "    \n",
    "    lab= cv2.cvtColor(bgr_imb, cv2.COLOR_BGR2LAB)\n",
    "    # Split lab image to different channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    \n",
    "    #Convert image from LAB Color model to RGB model\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return final\n",
    "\n",
    "def intersectLines(pt1, pt2, ptA, ptB): \n",
    "    \"\"\" this returns the intersection of Line(pt1,pt2) and Line(ptA,ptB)\n",
    "        https://www.cs.hmc.edu/ACM/lectures/intersections.html    \n",
    "        \n",
    "        returns a tuple: (xi, yi, valid, r, s), where\n",
    "        (xi, yi) is the intersection\n",
    "        r is the scalar multiple such that (xi,yi) = pt1 + r*(pt2-pt1)\n",
    "        s is the scalar multiple such that (xi,yi) = pt1 + s*(ptB-ptA)\n",
    "            valid == 0 if there are 0 or inf. intersections (invalid)\n",
    "            valid == 1 if it has a unique intersection ON the segment    \"\"\"\n",
    "\n",
    "    DET_TOLERANCE = 0.00000001\n",
    "\n",
    "    # the first line is pt1 + r*(pt2-pt1)\n",
    "    # in component form:\n",
    "    x1, y1 = pt1;   x2, y2 = pt2\n",
    "    dx1 = x2 - x1;  dy1 = y2 - y1\n",
    "\n",
    "    # the second line is ptA + s*(ptB-ptA)\n",
    "    x, y = ptA;   xB, yB = ptB;\n",
    "    dx = xB - x;  dy = yB - y;\n",
    "\n",
    "    # we need to find the (typically unique) values of r and s\n",
    "    # that will satisfy\n",
    "    #\n",
    "    # (x1, y1) + r(dx1, dy1) = (x, y) + s(dx, dy)\n",
    "    #\n",
    "    # which is the same as\n",
    "    #\n",
    "    #    [ dx1  -dx ][ r ] = [ x-x1 ]\n",
    "    #    [ dy1  -dy ][ s ] = [ y-y1 ]\n",
    "    #\n",
    "    # whose solution is\n",
    "    #\n",
    "    #    [ r ] = _1_  [  -dy   dx ] [ x-x1 ]\n",
    "    #    [ s ] = DET  [ -dy1  dx1 ] [ y-y1 ]\n",
    "    #\n",
    "    # where DET = (-dx1 * dy + dy1 * dx)\n",
    "    #\n",
    "    # if DET is too small, they're parallel\n",
    "    #\n",
    "    DET = (-dx1 * dy + dy1 * dx)\n",
    "\n",
    "    if math.fabs(DET) < DET_TOLERANCE: return (0,0,0,0,0)\n",
    "\n",
    "    # now, the determinant should be OK\n",
    "    DETinv = 1.0/DET\n",
    "\n",
    "    # find the scalar amount along the \"self\" segment\n",
    "    r = DETinv * (-dy  * (x-x1) +  dx * (y-y1))\n",
    "\n",
    "    # find the scalar amount along the input line\n",
    "    s = DETinv * (-dy1 * (x-x1) + dx1 * (y-y1))\n",
    "\n",
    "    # return the average of the two descriptions\n",
    "    xi = (x1 + r*dx1 + x + s*dx)/2.0\n",
    "    yi = (y1 + r*dy1 + y + s*dy)/2.0\n",
    "    return ( xi, yi, 1, r, s )\n",
    "\n",
    "def line(p1, p2):\n",
    "    A = (p1[1] - p2[1])\n",
    "    B = (p2[0] - p1[0])\n",
    "    C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "    return A, B, -C\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return x,y\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def rotate_image(img, center, angle, width, height):\n",
    "\n",
    "   shape = (img.shape[1], img.shape[0]) # (length, height)\n",
    "\n",
    "   matrix = cv2.getRotationMatrix2D((center[0], center[1]), angle, 1 )\n",
    "   rotated = cv2.warpAffine( img, matrix, shape )\n",
    "\n",
    "   x = int( center[0] - width/2  )\n",
    "   y = int( center[1] - height/2 )\n",
    "\n",
    "   cropped = rotated[ y:y+height, x:x+width ]\n",
    "\n",
    "   return cropped\n",
    "\n",
    "def getTruthValueFromFile(filename):\n",
    "    if filename is None:\n",
    "        return []\n",
    "    truth_values = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line != 'pos' and line != 'neg':\n",
    "                raise Exception('Truth file contains line other than \"pos\" or \"neg\"')\n",
    "            if line == 'pos':                    \n",
    "                truth_values.append(1)\n",
    "            else:\n",
    "                truth_values.append(0)\n",
    "    return truth_values\n",
    "\n",
    "def score_confidence_interval(score_fun, y_true, y_pred, pvalue, niter):\n",
    "    \"\"\"\n",
    "    Calculation of the confidence interval for a given p-value using bootstrap sampling\n",
    "    http://stackoverflow.com/questions/19124239/scikit-learn-roc-curve-with-confidence-intervals\n",
    "    \"\"\"\n",
    "    \n",
    "    n_bootstraps = niter\n",
    "    bootstrapped_scores = []\n",
    "    \n",
    "#     rng_seed = 42  # control reproducibility\n",
    "#     rng = np.random.RandomState(rng_seed)\n",
    "\n",
    "    rng = np.random.RandomState()\n",
    "    for i in range(n_bootstraps):\n",
    "        # bootstrap by sampling with replacement on the prediction indices\n",
    "        indices = rng.randint(0, len(y_pred) - 1, len(y_pred))\n",
    "        \n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            # We need at least one positive and one negative sample for ROC AUC\n",
    "            # to be defined: reject the sample\n",
    "            continue\n",
    "\n",
    "        score = score_fun(y_true[indices], y_pred[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "    \n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "\n",
    "    confidence_lower = sorted_scores[int((1 - pvalue) * len(sorted_scores))] \n",
    "    confidence_upper = sorted_scores[int(pvalue * len(sorted_scores))]\n",
    "\n",
    "    return [confidence_lower, confidence_upper]\n",
    "\n",
    "def auc_confidence_interval(y_true, y_pred, pvalue=0.95, niter=1000):\n",
    "    return score_confidence_interval(roc_auc_score, y_true, y_pred, pvalue, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual detection code, all in a single function:\n",
    "\n",
    "def getmin(data):\n",
    "    half = int(data.shape[0]/2)\n",
    "    top = data.shape[0]\n",
    "    values = np.array([])\n",
    "    for i in range(half, top):\n",
    "        values = np.append(values, np.mean(data[i]))\n",
    "    m = np.min(values)\n",
    "    sd = np.std(values)\n",
    "    return m, sd\n",
    "\n",
    "def predict(data, mint, maxt):\n",
    "    m, sd = getmin(data)\n",
    "    f = (m - mint) / (maxt - mint)\n",
    "    if f < 0: f = 0\n",
    "    if 1 < f: f = 1\n",
    "    score = 1 - f\n",
    "    return score\n",
    "\n",
    "def getPredictions(filename):\n",
    "    # The maximum and minimum allowed ratios of the sides of the green box\n",
    "    maxGreenBoxRatio = 140.0/528\n",
    "    minGreenBoxRatio = 102.0/578\n",
    "\n",
    "    # The maximum allowed ratio of the sides of the final deteted strip\n",
    "    maxStripBoxRatio = 70/480\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the sides of the box defined by the red arrows\n",
    "    maxRedBoxRatio = 42.0/91\n",
    "    minRedBoxRatio = 14.0/104\n",
    "\n",
    "    # The maximum and minimum allowed ratios of the areas of green boxes and red arrow-bounding boxes\n",
    "    maxRedGreenBoxRatio = 3500.0/4000\n",
    "    minRedGreenBoxRatio = 2000.0/4500\n",
    "    # minRedGreenIntersection = 1000.0/4500\n",
    "\n",
    "    # Minimum intensity for binary thresholding of the top portion of the strips\n",
    "    minStripThreshold = 190\n",
    "\n",
    "    # Sensitive area of the strip\n",
    "    stripWidth = 200\n",
    "    stripHeight = 2000\n",
    "    stripHoldY = 900\n",
    "    # maxPeakAlign = 50\n",
    "\n",
    "    # Percentage of the margins to be removed\n",
    "    marginFraction = 0.2\n",
    "\n",
    "    # Red is at the beginning/end of the hue range, so it covers the [0-15] and the [170, 180] \n",
    "    # (hue in OpenCV varies  between 0 and 180 degrees)\n",
    "    lower_red1 = np.array([0, 50, 50]) \n",
    "    upper_red1 = np.array([13, 255, 255])\n",
    "    lower_red2 = np.array([170, 50, 50]) \n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Green is between 20 and 90 (these ranges can be adjusted)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "\n",
    "    # We can also use a large color range to encapsulate both red and green:\n",
    "    lower_redgreen1 = np.array([0, 50, 50]) \n",
    "    upper_redgreen1 = np.array([83, 255, 255])\n",
    "    lower_redgreen2 = np.array([170, 50, 50]) \n",
    "    upper_redgreen2 = np.array([180, 255, 255])    \n",
    "    \n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    \n",
    "    # Processing Step 1: detecting the colored area in the strips\n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    # First, use CLAHE to improve image quality:\n",
    "    # plt.subplot(2, 1, 1)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # image = applyClahetoRGB(image)\n",
    "    # plt.subplot(2, 1, 2)\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # First, convert the image to HSV color space, which makes the color detection straightforward\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # These strips have red arrows on a green background, so we define two masks, one for red and the other for green\n",
    "\n",
    "    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1) \n",
    "    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2) \n",
    "\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    red_mask = red_mask1 + red_mask2\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    redgreen_mask1 = cv2.inRange(hsv, lower_redgreen1, upper_redgreen1) \n",
    "    redgreen_mask2 = cv2.inRange(hsv, lower_redgreen2, upper_redgreen2) \n",
    "    mask = redgreen_mask1 + redgreen_mask2\n",
    "      \n",
    "    # Processing Step 2a: determining the bounding boxes for the red arrows.\n",
    "    # Because the red hue seems to be well-conserved between images,\n",
    "    # we have a high confidence of putting a box around all the red arrows. \n",
    "    cnts = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    red_boxes = []\n",
    "    red_rectangles = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( top-left corner(x,y),  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        redBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if redBoxRatio < minRedBoxRatio or maxRedBoxRatio < redBoxRatio: continue\n",
    "        red_boxes += [box[0:]]\n",
    "        red_rectangles += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 3, (255,0,0), -1)    \n",
    "    \n",
    "    # Processing Step 2b: finding green box candidates\n",
    "    # Stage 1:\n",
    "    #     Given a masked version of the image which includes red to green hues,\n",
    "    #     find all green contours\n",
    "    # Stage 2:\n",
    "    #     Declare a green contour to be a green_rect_candidate to be further \n",
    "    #     analyzed if the ratio of the sides of the contour are similar to that\n",
    "    #     observed in the Sherlock strips. \n",
    "    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    green_box_candidates = []\n",
    "    green_rect_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        # rect is a tuple with the following details:\n",
    "        #    ( (x,y) of middle of top side of rect,  (width,height),  angle of rotation )\n",
    "        # As such, we can easily get the ratio of the sides of the detected boxes; note\n",
    "        # that because for our purpose the sides are categorized into width and height\n",
    "        # arbitrarily, we take the ratio of the sides as the lesser ratio:\n",
    "        greenBoxRatio = min(rect[1][0]/rect[1][1], rect[1][1]/rect[1][0])\n",
    "        if greenBoxRatio < minGreenBoxRatio or maxGreenBoxRatio < greenBoxRatio: continue\n",
    "\n",
    "        area = boxArea(box)\n",
    "        green_box_candidates += [box[0:]]\n",
    "        green_rect_candidates += [rect]\n",
    "\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 2c: filter the green_box_candidates based on size (imputed from\n",
    "    # the red box areas) and shape (ratio of lengths of the sides).\n",
    "    # Stage 1:\n",
    "    #     Mark all candidate green boxes which are within a particular size range\n",
    "    #     of a red box. Because we can put bounding boxes around red arrows with a \n",
    "    #     high confidence, and there is little-to-no red hue in the source image \n",
    "    #     excluding the red arrows, we can impute that the largest of these marked\n",
    "    #     are the green boxes around the arrows (the contrary would suggest a large\n",
    "    #     green spot in the source image, or some severe hue errors)\n",
    "    # Stage 2:\n",
    "    #     Sort the marked boxes by size; chose the second largest marked box as a\n",
    "    #     representative green box\n",
    "    # Stage 3:\n",
    "    #     Filter out marked green boxes which are not a similar size as the\n",
    "    #     representative green box.\n",
    "\n",
    "    green_boxes = {}\n",
    "    green_rects = {}\n",
    "    for i, red_box in enumerate(red_boxes):\n",
    "        red_box_area = boxArea(red_box)*1.0\n",
    "        for j, green_box in enumerate(green_box_candidates):\n",
    "            green_box_area = boxArea(green_box)*1.0\n",
    "            redGreenBoxRatio = red_box_area/green_box_area\n",
    "            if minRedGreenBoxRatio < redGreenBoxRatio < maxRedGreenBoxRatio:\n",
    "                # now check for intersections:\n",
    "                green_boxes[j] = True\n",
    "                green_rects[j] = True\n",
    "\n",
    "    green_boxes = [green_box_candidates[j] for j in green_boxes]\n",
    "    green_rects = [green_rect_candidates[j] for j in green_rects]\n",
    "    green_boxes.sort(key = lambda box : boxArea(box), reverse=True)\n",
    "    green_rects.sort(key = lambda rect : rectArea(rect), reverse=True)\n",
    "\n",
    "    if len(green_rects) < 2:\n",
    "        raise Exception('Not enough strips')\n",
    "    if rectArea(green_rects[0]) < 1.25* rectArea(green_rects[1]):\n",
    "        greenBoxArea = rectArea(green_rects[1])\n",
    "        green_rect_len = max(green_rects[1][1][0], green_rects[1][1][1])\n",
    "    elif len(green_boxes) < 3 \\\n",
    "            and rectArea(green_rects[1]) < 1.25* rectArea(green_rects[2]):\n",
    "        greenBoxArea = rectArea(green_rects[2])\n",
    "        green_rect_len = max(green_rects[2][1][0], green_rects[2][1][1])\n",
    "    else:\n",
    "        raise Exception('Too much noise in image')\n",
    "\n",
    "    center_boxes = [box for box in green_boxes \n",
    "                     if 0.8*greenBoxArea < boxArea(box) < 1.25*greenBoxArea]\n",
    "    greenBoxArea = statistics.median([boxArea(box) for box in center_boxes])\n",
    "\n",
    "    # Processing Step 3: binary thresholding of the entire image to extract the top part of the strips\n",
    "    ret, thresh = cv2.threshold(image, minStripThreshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Processing Step 4: detect boundary boxes for the top of the strips\n",
    "    grayscale = cv2.cvtColor(thresh, cv2.COLOR_BGR2GRAY)\n",
    "    cnts = cv2.findContours(grayscale, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "\n",
    "    # Minimum area of the top strip boxes\n",
    "    minTopBoxArea = 1.8 * greenBoxArea\n",
    "    # Maximum of the top strip boxes\n",
    "    maxTopBoxArea = 5 * greenBoxArea\n",
    "\n",
    "    top_box_candidates = []\n",
    "    top_rects_candidates = []\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0: continue\n",
    "\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = makeOrderedBox(rect)\n",
    "\n",
    "        area = boxArea(box)\n",
    "        if area < minTopBoxArea/15 or maxTopBoxArea < area: \n",
    "            continue\n",
    "\n",
    "        top_box_candidates += [box]\n",
    "        top_rects_candidates += [rect]\n",
    "    \n",
    "    # In some cases, the strip signal is so strong that a continuous box gets split up into two boxes. \n",
    "    # We fix this by merging two boxes if the bottom left and top left corners of the respective boxes,\n",
    "    # and the  right and top right corners of the respective boxes are within a threshold distance of\n",
    "    # # each other. \n",
    "    top_boxes = []\n",
    "    top_box_candidates.sort(key = lambda item : item[1][1])\n",
    "    distance_threshold = green_rect_len * 0.15\n",
    "    merged_boxes = {}\n",
    "    tmp = image.copy()\n",
    "    for i in range(0, len(top_box_candidates)):\n",
    "        upper_box = top_box_candidates[i]\n",
    "        if i in merged_boxes:\n",
    "            continue\n",
    "        current_merged_upper_box = upper_box\n",
    "        for j in range(i, len(top_box_candidates)):\n",
    "            lower_box = top_box_candidates[j]\n",
    "            if pointDistance(current_merged_upper_box[3], lower_box[0]) < distance_threshold and \\\n",
    "                    pointDistance(current_merged_upper_box[2], lower_box[1]) < distance_threshold:\n",
    "                # Sometimes the arrows get detected in this step as false boxes -- to filter for this, \n",
    "                # we make sure that boxes can only be concatenated if they have similar width:\n",
    "                if pointDistance(current_merged_upper_box[3], current_merged_upper_box[2]) < \\\n",
    "                        pointDistance(lower_box[0], lower_box[1])*1.5:\n",
    "                    current_merged_upper_box = np.array([current_merged_upper_box[0], \n",
    "                                                         current_merged_upper_box[1], \n",
    "                                                         lower_box[2], lower_box[3]])\n",
    "\n",
    "                    if minTopBoxArea < boxArea(current_merged_upper_box): \n",
    "                        merged_boxes[j] =  True\n",
    "        else:\n",
    "            stripBoxRatio = pointDistance(current_merged_upper_box[0], \n",
    "                                          current_merged_upper_box[1])/ \\\n",
    "                                          pointDistance(current_merged_upper_box[0],\n",
    "                                                        current_merged_upper_box[3])\n",
    "            if minTopBoxArea < boxArea(current_merged_upper_box) and \\\n",
    "                    stripBoxRatio < maxStripBoxRatio: \n",
    "                top_boxes.append(current_merged_upper_box) \n",
    "\n",
    "    for box in top_boxes:\n",
    "        tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 5)\n",
    "        tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 20, (255,0,0), -1)\n",
    "    \n",
    "    # Processing Step 5: construct the boxes that enclose the sensitive strip area\n",
    "    # First, order the top boxes from left to right\n",
    "    top_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "    # Find the red boxes which bound arrows, and then\n",
    "    # order them left to right\n",
    "    red_boxes.sort(key=lambda box: boxArea(box), reverse=True)\n",
    "    red_boxes = red_boxes[0:len(top_boxes)]\n",
    "    red_boxes.sort(key=lambda box: box[0][0], reverse=False)\n",
    "\n",
    "    # Create a copy of the original image to draw the bounding boxes on\n",
    "    tmp = image.copy()\n",
    "    num_boxes = len(top_boxes)\n",
    "    strip_boxes = []\n",
    "    for i in range(0, num_boxes):\n",
    "        tbox = top_boxes[i]\n",
    "        rbox = red_boxes[i]    \n",
    "\n",
    "        # The corners are expected to be received in the following order:\n",
    "        # 0 = botton left corner\n",
    "        # 1 = top left corner   \n",
    "        # 2 = top right corner \n",
    "        # 3 = bottom right corner\n",
    "\n",
    "        tp0, tp1, tp2, tp3 = tbox[3], tbox[0], tbox[1], tbox[2]\n",
    "        rp0, rp1, rp2, rp3 = rbox[3], rbox[0], rbox[1], rbox[2]\n",
    "\n",
    "        # The intersection of the lines defining the sides of the strip (tp1-tp0 and tp2-tp3)\n",
    "        # with the bottom edge of the red box defines the bottom corners of the area of interest\n",
    "        res1 = intersection(line(tp1, tp0), line(rp0, rp3))\n",
    "        res2 = intersection(line(tp2, tp3), line(rp0, rp3)) \n",
    "\n",
    "        assert(res1 != False and res2 != False), \"Top and center boxes are not intersecting\"\n",
    "\n",
    "        p1 = np.array([int(round(res1[0])), int(round(res1[1]))])\n",
    "        p2 = np.array([int(round(res2[0])), int(round(res2[1]))])\n",
    "\n",
    "        sbox = np.array([p1, tp1, tp2, p2])\n",
    "        strip_boxes += [sbox]\n",
    "    \n",
    "    # Processing Step 6: Extract the strips into separate images\n",
    "    ref_box = np.array([[0, 0],[0, stripHeight],[stripWidth, stripHeight],[stripWidth, 0]], dtype=float)\n",
    "    lower_green = np.array([20, 50, 50]) \n",
    "    upper_green = np.array([83, 255, 255])\n",
    "#     fig, plots = plt.subplots(1, len(strip_boxes)*3, figsize=(10, 10))\n",
    "    idx = 0\n",
    "    tmp = image.copy()\n",
    "    raw_strip_images = []\n",
    "    for sbx in strip_boxes:\n",
    "        center = (statistics.mean([sbx[0][0], sbx[1][0], sbx[2][0], sbx[3][0]]),\n",
    "                  statistics.mean([sbx[0][1], sbx[1][1], sbx[2][1], sbx[3][1]]))\n",
    "        angle = -1*np.degrees(np.arctan2(sbx[0][0]-sbx[1][0], sbx[0][1] - sbx[1][1]))\n",
    "        #angle = angle if sbx[0][0] < sbx[1][0] else angle*-1\n",
    "        width = int(pointDistance(sbx[1], sbx[2]))\n",
    "        height = int(pointDistance(sbx[0], sbx[1]))\n",
    "#         print(angle)\n",
    "#         print(width)\n",
    "        straigtened_strip = rotate_image(image, center, angle, width, \n",
    "                                                    height)\n",
    "        # Spurious hits often occur at the edges of the strip, so let's\n",
    "        # crop them away\n",
    "        cropped_strip = straigtened_strip[:, \n",
    "                                          int(straigtened_strip.shape[1]*0.1):\n",
    "                                          int(straigtened_strip.shape[1]*0.9)]\n",
    "\n",
    "#         plots[idx].imshow(cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        hsv = cv2.cvtColor(cropped_strip, cv2.COLOR_BGR2HSV)\n",
    "        green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        cnts = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        # Create a copy of the image to draw the bounding boxes on\n",
    "        tmp = cropped_strip.copy()\n",
    "        colored_box_cutoff = tmp.shape[0]\n",
    "        for c in cnts:\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0: continue\n",
    "\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = makeOrderedBox(rect)\n",
    "            if boxArea(box) > 0.10*greenBoxArea:\n",
    "                if box[0][1] < colored_box_cutoff:\n",
    "                    colored_box_cutoff = box[0][1]\n",
    "            tmp = cv2.drawContours(tmp, [box], 0, (0,0,255), 10)\n",
    "            tmp = cv2.circle(tmp, (box[0][0], box[0][1]), 10, (255,0,0), -1)\n",
    "        #plots[idx + 0].imshow(cv2.cvtColor(green_mask, cv2.COLOR_BGR2RGB))\n",
    "#         plots[idx + 0].imshow(cv2.cvtColor(tmp, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        colored_box_cutoff = colored_box_cutoff\n",
    "        final_strip = straigtened_strip[0:colored_box_cutoff, :]\n",
    "#         plots[idx + 1].imshow(cv2.cvtColor(final_strip, cv2.COLOR_BGR2RGB))\n",
    "    #     h, status = cv2.findHomography(final_strip, ref_box)\n",
    "    #     img = cv2.warpPerspective(image, h, (stripWidth, stripHeight))\n",
    "    #     raw_strip_images += [img]\n",
    "        height = final_strip.shape[0]\n",
    "        width = final_strip.shape[1]\n",
    "        h, status = cv2.findHomography(np.array([(0,height), (0,0), (width, 0), (width, height)]), ref_box)\n",
    "        img = cv2.warpPerspective(final_strip, h, (stripWidth, stripHeight))\n",
    "        raw_strip_images += [img]\n",
    "#         plots[idx + 2].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        idx += 3    \n",
    "    \n",
    "    # Processing Step 7: Crop the images to remove the grip of the strips, and the vertical borders\n",
    "    norm_strip_images = []\n",
    "#     fig, plots = plt.subplots(1, len(raw_strip_images), figsize=(10, 10))\n",
    "    idx = 0\n",
    "    for img in raw_strip_images:\n",
    "        # Crop out the top and the bottom parts of the strip, and applying bilateral filtering for smoothing\n",
    "        # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
    "        x0 = int(marginFraction * stripWidth)\n",
    "        x1 = int((1 - marginFraction) * stripWidth)\n",
    "        y0 = 0\n",
    "        y1 = stripHoldY\n",
    "\n",
    "        crop = img[y0:y1, x0:x1]\n",
    "        nimg = cv2.bilateralFilter(crop, 9, 75, 75)\n",
    "        nimg = nimg[30:, :]\n",
    "        norm_strip_images += [nimg]\n",
    "\n",
    "        vimg = cv2.flip(nimg, 0)\n",
    "#         if idx == 1: plots[idx].axis('off')\n",
    "#         plots[idx].imshow(cv2.cvtColor(vimg, cv2.COLOR_BGR2RGB))\n",
    "        idx += 1    \n",
    "    \n",
    "    # Processing Step 7b: Normalize HSV values\n",
    "    correction_method = 'clahe' # {'linear', 'clahe', 'gray', 'he'}\n",
    "    idx = 0\n",
    "    hew_corrected_norm_strip_images = []\n",
    "    for nimg in norm_strip_images:\n",
    "        hsv = cv2.cvtColor(nimg, cv2.COLOR_BGR2HSV)\n",
    "        # determine the hsv color of this strip\n",
    "        if correction_method == 'linear':\n",
    "            # We chose a standard hsv value to normalize all of our images to:\n",
    "            standard_hsv = [16.0/1.5, 17.0/1.5, 243.0/1.5]\n",
    "            # standard_hsv = [16.0, 17.0, 243.0]\n",
    "\n",
    "            rows_hsv = []\n",
    "            for i in range(hsv.shape[0]):\n",
    "                pixels_h = np.zeros(hsv.shape[1])\n",
    "                pixels_s = np.zeros(hsv.shape[1])\n",
    "                pixels_v = np.zeros(hsv.shape[1])\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    pixels_h[j] = hsv[i,j][0]\n",
    "                    pixels_s[j] = hsv[i,j][1]\n",
    "                    pixels_v[j] = hsv[i,j][2]\n",
    "                rows_hsv.append([statistics.median(val) for val in [pixels_h, pixels_s, pixels_v]])\n",
    "                #print(rows_hsv)\n",
    "            rows_hsv = np.array(rows_hsv)\n",
    "            strip_hsv = [statistics.median(rows_hsv[:,0]), \n",
    "                               statistics.median(rows_hsv[:,1]),\n",
    "                               statistics.median(rows_hsv[:,2])]\n",
    "            hue_correction = standard_hsv[0]/strip_hsv[0]\n",
    "            sat_correction = standard_hsv[1]/strip_hsv[1]\n",
    "            val_correction = standard_hsv[2]/strip_hsv[2]\n",
    "            for i in range(hsv.shape[0]):\n",
    "                for j in range(hsv.shape[1]):\n",
    "                    # hsv[i,j][0] = min(179, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][0] = min(180, hsv[i,j][0] * hue_correction)\n",
    "                    hsv[i,j][1] = hsv[i,j][1] * sat_correction\n",
    "                    hsv[i,j][2] = hsv[i,j][2] * val_correction\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_BGR2RGB\n",
    "\n",
    "        elif correction_method == 'clahe':\n",
    "            clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(10,10))\n",
    "            hew_corrected_norm_strip_images.append(clahe.apply(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB        \n",
    "\n",
    "        elif correction_method == 'he':\n",
    "            hew_corrected_norm_strip_images.append(\n",
    "                cv2.equalizeHist(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        elif correction_method == 'gray':\n",
    "            hew_corrected_norm_strip_images.append(cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY))\n",
    "            vimg = cv2.flip(hew_corrected_norm_strip_images[-1],0)\n",
    "            vimg_color = cv2.COLOR_GRAY2RGB\n",
    "\n",
    "        else:\n",
    "            raise Exception('incorrect normalization type')\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "    # Processing Step 8: make prediction\n",
    "    idx = len(norm_strip_images) - 1\n",
    "    min0 = 0\n",
    "    img0 = hew_corrected_norm_strip_images[idx]\n",
    "    data0 = img0.astype('int32')\n",
    "    min0, _ = getmin(data0)\n",
    "    mint = min0 - LODStandardDeviation\n",
    "    maxt = min0 + LODStandardDeviation\n",
    "\n",
    "    preds = []\n",
    "    for img in hew_corrected_norm_strip_images:\n",
    "        data = img.astype('int32') \n",
    "        nrows = data.shape[0]\n",
    "        if not idx == 0:\n",
    "            pred = predict(data, mint, maxt)\n",
    "#             print(pred)\n",
    "            preds += [pred]\n",
    "        idx -= 1\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/SL-IV-1.jpg\n",
      "[1, 1, 0, 1, 0, 1, 0]\n",
      "[1, 1, 0.3088709677419351, 1, 0.5663978494623653, 1]\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "all_truths = []\n",
    "for test in test_files:\n",
    "    img_fn = 'images/' + test + \".jpg\"\n",
    "    tru_fn = 'images/' + test + \".txt\"\n",
    "\n",
    "    t = getTruthValueFromFile(tru_fn)\n",
    "    s = getPredictions(img_fn)\n",
    "    all_scores += s\n",
    "    all_truths += t[:-1]\n",
    "    print(img_fn)\n",
    "    print(t)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strips   : 6\n",
      "Number of positives: 4\n",
      "Perc. of positives : 66.67\n",
      "\n",
      "Measures of performance\n",
      "AUC           : 1.00 (1.00, 1.00)\n",
      "Brier         : 0.07\n",
      "Accuracy      : 0.83\n",
      "Sensitivity   : 1.00\n",
      "Specificity   : 0.50\n"
     ]
    }
   ],
   "source": [
    "class_threshold = 0.5\n",
    "p_value = 0.95\n",
    "all_preds = np.array([int(class_threshold < p) for p in all_scores])\n",
    "\n",
    "ytrue = np.array(all_truths)\n",
    "probs = np.array(all_scores)\n",
    "ypred = all_preds\n",
    "\n",
    "auc = roc_auc_score(ytrue, probs)\n",
    "fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "brier = brier_score_loss(ytrue, probs)\n",
    "# cal, dis = caldis(ytrue, probs)\n",
    "acc = accuracy_score(ytrue, ypred)\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(ytrue, ypred)\n",
    "\n",
    "auc_ci = auc_confidence_interval(ytrue, probs, p_value)\n",
    "\n",
    "P = N = 0\n",
    "TP = TN = 0\n",
    "FP = FN = 0\n",
    "for i in range(len(ytrue)):\n",
    "    if ytrue[i] == 1:\n",
    "        P += 1\n",
    "        if ypred[i] == 1: TP += 1\n",
    "        else: FN += 1\n",
    "    else:\n",
    "        N += 1\n",
    "        if ypred[i] == 0: TN += 1\n",
    "        else: FP += 1\n",
    "            \n",
    "sens = float(TP)/P\n",
    "spec = float(TN)/N\n",
    "\n",
    "# Positive and Negative Predictive Values\n",
    "# https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values\n",
    "ppv = float(TP) / (TP + FP)\n",
    "npv = float(TN) / (TN + FN)\n",
    "        \n",
    "# Likelihood ratios\n",
    "# https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing\n",
    "lr_pos = sens / (1 - spec) if spec < 1 else np.inf\n",
    "lr_neg = (1 - sens) / spec if 0 < spec else np.inf\n",
    "\n",
    "# print \"True outcomes:\", ytrue\n",
    "# print \"Prediction   :\", ypred\n",
    "cfr = 100 * (float(np.sum(ytrue)) / len(ytrue))\n",
    "print(\"Number of strips   :\", len(ytrue))\n",
    "print(\"Number of positives:\", np.sum(ytrue)) \n",
    "print(\"Perc. of positives : %0.2f\" % cfr)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Measures of performance\") \n",
    "print(\"AUC           : %0.2f (%0.2f, %0.2f)\" % (auc, auc_ci[0], auc_ci[1])) \n",
    "print(\"Brier         : %0.2f\" % brier) \n",
    "# print(\"Calibration   :\", cal) \n",
    "# print(\"Discrimination:\", dis) \n",
    "print(\"Accuracy      : %0.2f\" % acc) \n",
    "print(\"Sensitivity   : %0.2f\" % sens) \n",
    "print(\"Specificity   : %0.2f\" % spec) \n",
    "# print(\"PPV           : %0.2f\" % ppv) \n",
    "# print(\"NPV           : %0.2f\" % npv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sensitivity')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.plot([0, 1], [0, 1], 'k--', c='grey')\n",
    "plt.plot(fpr, tpr, color='black')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "# fig.savefig(os.path.join(model_name, 'drc-roc-complete-' + ct_type + '.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
